{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsUmsD35Lu60"
   },
   "source": [
    "# PPO in Gym Lunar Lander\n",
    "\n",
    "This notebook will have the implementation for PPO applied to Gym environment for later using it to the Transformer problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZPS3p1umLu68"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import activations\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QCi-HfazMOaJ"
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LU_0Whh1MaaQ"
   },
   "outputs": [],
   "source": [
    "ENV_NAME = 'LunarLanderContinuous-v2'\n",
    "CONTINUOUS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0Kit5RtLu7B"
   },
   "source": [
    "## Reinforcement Learning\n",
    "In the section below, a reinforcement learning agent shall be implemented and trained to perform a landing in the environment defined above. The reward function is already given.\n",
    "\n",
    "The agent that will be implemented in this notebook is a PPO agent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Wbn4_DiLu7D"
   },
   "source": [
    "###  Actor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xQJ7FyvVLu7F"
   },
   "outputs": [],
   "source": [
    "def get_value_network(input_size):\n",
    "    '''\n",
    "    In this case, the input should be the env.observation_space.shape[0]\n",
    "    '''\n",
    "    x = keras.Input(input_size)\n",
    "    \n",
    "    v = Dense(10*input_size[0], activation = 'relu')(x)\n",
    "    v = Dense(30, activation = 'relu')(v)\n",
    "    v = Dense(17, activation = 'relu')(v)\n",
    "    v = Dense(5, activation = 'relu')(v)\n",
    "    v = Dense(1, activation = 'linear')(v)\n",
    "    \n",
    "    model = keras.Model(x,v)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zOluKdaALu7F"
   },
   "outputs": [],
   "source": [
    "def get_policy_network(agent, input_size, output_size):\n",
    "    '''\n",
    "    Input: env.observation_space.shape \n",
    "    Output_size: should be env.action_space.shape[0]\n",
    "    '''\n",
    "    input_x = keras.Input(input_size)\n",
    "    \n",
    "    x = Dense(10*input_size[0],activation='relu')(input_x)\n",
    "    x = Dense(100,activation='relu')(x)\n",
    "    x = Dense(50,activation='relu')(x)\n",
    "    x = Dense(10*output_size[0],activation='relu')(x)\n",
    "\n",
    "    mu = Dense(output_size[0], activation = 'tanh')(x)\n",
    "    log_std = Dense(output_size[0], activation = 'linear')(x) # We get the logarithm of the std\n",
    "\n",
    "    model = keras.Model(input_x,[mu, log_std])\n",
    "    \n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5xAs5ffnLu7F"
   },
   "outputs": [],
   "source": [
    "def get_actions(mu, log_std):\n",
    "    log_std = tf.clip_by_value(log_std, -9, 2)\n",
    "    std = tf.exp(log_std)\n",
    "    gaussian = tfp.distributions.Normal(loc = mu, scale = std)\n",
    "    actions = gaussian.sample(1)\n",
    "    \n",
    "    #####\n",
    "    #print('_ _ _ _ _ _')\n",
    "    #print('GET ACTIONS')\n",
    "    #print('actions shape', actions.shape)\n",
    "    #print('actions before squeeze', actions)\n",
    "    #print('_ _ _ _ _ _')\n",
    "    #####\n",
    "    \n",
    "    actions = tf.squeeze(actions,axis=0) # Corrected (before, axis = 1)\n",
    "    assert mu.shape == actions.shape, 'mu and actions shape is not the same, be careful with squeeze'\n",
    "    actions = tf.clip_by_value(actions,-1,1)\n",
    "    return actions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yc43QADBLu7G"
   },
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KVXTYkrKLu7G"
   },
   "outputs": [],
   "source": [
    "def calc_logprob(mu, log_std, action):\n",
    "    \n",
    "    #action = tf.squeeze(action,axis=1)\n",
    "    action = tf.cast(action, dtype=tf.float32)\n",
    "    \n",
    "    assert mu.shape == action.shape, 'mu and actions shape is not the same in calcprob: action ' + str(action.shape) + ' mu ' + str(mu.shape)\n",
    "    assert log_std.shape == action.shape, 'mu and actions shape is not the same in calcprob'\n",
    "    \n",
    "    #p1 = - tf.math.divide(((mu - action) ** 2),(2*tf.exp(log_std)))\n",
    "    #p2 = - tf.math.log(tf.math.sqrt(2 * np.pi * tf.exp(log_std)))\n",
    "    \n",
    "    #assert p1.shape == p2.shape, 'p1 and p2 have different shapes'\n",
    "    #assert not np.isinf(np.sum(p1.numpy())), 'p1 is infinite'\n",
    "    #assert not np.isinf(np.sum(p2.numpy())), 'p2 is infinite'\n",
    "    #assert tf.reduce_all(tf.math.is_nan(p1[0])) == False, \"p1 have NaNs\"\n",
    "    #assert tf.reduce_all(tf.math.is_nan(p2[0]))== False, \"p2 have NaNs\"\n",
    "\n",
    "    std = tf.exp(log_std) # Corrected\n",
    "    gaussian = tfp.distributions.Normal(loc = mu, scale = std) # Corrected\n",
    "    p3 = gaussian.log_prob(action) # Corrected\n",
    "    \n",
    "    assert not np.isinf(np.sum(p3.numpy())), 'log_prob is infinite'\n",
    "    \n",
    "    #####\n",
    "    #print('CALC_LOGPROB')\n",
    "    #print('action', action[0])\n",
    "    #print('mu', mu.shape)\n",
    "    #print('log_std', log_std.shape)\n",
    "    #print('p1', p1.shape)\n",
    "    #print('_______________')\n",
    "    #if tf.math.is_nan(tf.math.reduce_sum(p1)):\n",
    "        #print('p1',p1)\n",
    "        #print('mu',mu)\n",
    "    #if tf.math.is_nan(tf.math.reduce_sum(p2)):\n",
    "        #print('p2',p2)\n",
    "        #print('log_std',log_std)\n",
    "    #####\n",
    "\n",
    "    return p3 # Corrected (before, return p1+p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hI8dm25JLu7H"
   },
   "outputs": [],
   "source": [
    "def get_adv_ref(agent, trajectory):\n",
    "    # gives the adv and ref from a single trajectory\n",
    "    gamma = agent.gamma\n",
    "    gae_lambda = agent.gae_lambda\n",
    "\n",
    "    states, actions, rewards, terminals, next_states = map(list, zip(*trajectory))\n",
    "    \n",
    "    #####\n",
    "    #print('_ _ _ _ _ _ _')\n",
    "    #print('GET_ADV_REF')\n",
    "    #print('things when getting them from the trajectory')\n",
    "    #print('states shape',np.shape(states))\n",
    "    #print('states',states)\n",
    "    #print('actions shape',np.shape(actions))\n",
    "    #print('actions',actions)\n",
    "    #print('rewards shape',np.shape(rewards))\n",
    "    #print('rewards',rewards)\n",
    "    #####\n",
    "    \n",
    "    states = np.concatenate(states)\n",
    "    next_states = np.concatenate(next_states)\n",
    "    rewards = np.array(rewards)\n",
    "    \n",
    "    #####\n",
    "    #print('things after concatenating them:')\n",
    "    #print('states shape',states.shape)\n",
    "    #print('states',states)\n",
    "    #print('rewards shape',rewards.shape)\n",
    "    #print('rewards',rewards)\n",
    "    #####\n",
    "    \n",
    "    value_v = agent.critic(states)\n",
    "    \n",
    "    #####\n",
    "    #print('value function after NN')\n",
    "    #print('value_v shape', value_v.shape)\n",
    "    #print('value_v',value_v)\n",
    "    #####\n",
    "    \n",
    "    values = tf.squeeze(value_v).numpy()\n",
    "\n",
    "    next_value_v = agent.critic(next_states)\n",
    "    next_values = tf.squeeze(next_value_v).numpy()\n",
    "\n",
    "    #####\n",
    "    #print('value function after squeeze')\n",
    "    #print('value_v shape squeezed', value_v.shape)\n",
    "    #print('value_v squeezed',value_v)\n",
    "    #print('states when getting adv and ref',states.shape)\n",
    "    #print('values', values.shape)\n",
    "    #print('rewards in adv and ref', rewards.shape)\n",
    "    #print('next_values', values.shape)\n",
    "    #####\n",
    "\n",
    "    # generalized advantage estimator: smoothed version of the advantage\n",
    "    last_gae = 0.0\n",
    "    result_adv = []\n",
    "    result_ref = []\n",
    "    \n",
    "    for val, next_val, reward, terminal in zip(reversed(values),reversed(next_values),reversed(rewards),reversed(terminals)):\n",
    "        \n",
    "        #####\n",
    "        #print('inside the loop')\n",
    "        #print('val',val)\n",
    "        #print('next_val', next_val)\n",
    "        #print('reward',reward)\n",
    "        #print('terminal',terminal)\n",
    "        #####\n",
    "        \n",
    "        if terminal:\n",
    "            delta = reward - val\n",
    "            last_gae = delta\n",
    "            \n",
    "            #####\n",
    "            #print('inside the if')\n",
    "            #print('delta',delta)\n",
    "            #print('last_gae',last_gae)\n",
    "            #####\n",
    "            \n",
    "        else:\n",
    "            delta = reward + gamma*next_val - val\n",
    "            last_gae = delta + gamma*gae_lambda*last_gae\n",
    "            \n",
    "            #####\n",
    "            #print('inside the else')\n",
    "            #print('delta',delta)\n",
    "            #print('last_gae',last_gae)\n",
    "            #####\n",
    "\n",
    "        result_adv.append(last_gae)\n",
    "        result_ref.append(last_gae + val)\n",
    "\n",
    "        #####\n",
    "        #print('element in adv',last_gae)\n",
    "        #print('element in ref', last_gae + val)\n",
    "        #print('_______________')\n",
    "        #####    \n",
    "    \n",
    "    #####\n",
    "    #print('adv_v NOT reversed shape',np.shape(result_adv))\n",
    "    #print('adv_v NOT reversed',result_adv)\n",
    "    #print('ref_v NOT reversed shape',np.shape(result_ref))\n",
    "    #print('ref_v NOT reversed',result_ref)\n",
    "    #####\n",
    "    \n",
    "    adv_v = list(reversed(result_adv))\n",
    "    ref_v = list(reversed(result_ref))\n",
    "    \n",
    "    #####\n",
    "    #print('adv_v reversed shape',np.shape(adv_v))\n",
    "    #print('adv_v reversed',adv_v)\n",
    "    #print('ref_v reversed shape',np.shape(ref_v))\n",
    "    #print('ref_v reversed',ref_v)\n",
    "    #print('_ _ _ _ _ _ _')\n",
    "    #####\n",
    "    \n",
    "    return adv_v, ref_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cUj1w8AoLu7H"
   },
   "outputs": [],
   "source": [
    "def loss_critic(ref_val,value_v):\n",
    "    loss = tf.keras.losses.MSE(value_v,ref_val)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_9TB5XaLu7H"
   },
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UjyvTlevLu7I"
   },
   "outputs": [],
   "source": [
    "def optimize_network(agent,states,actions,adv_batch,ref_batch,batch_old_logprob_v):\n",
    "    with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
    "\n",
    "        # critic training\n",
    "        value_v = agent.critic(states)\n",
    "        assert ref_batch.shape == value_v.shape, \"ref_batch and value_v have different shapes\"\n",
    "        loss_value_v = loss_critic(ref_batch,value_v)\n",
    "\n",
    "        # actor training\n",
    "        mu, log_std = agent.actor(states)\n",
    "        log_std = tf.clip_by_value(log_std, -9, 2)\n",
    "        logprob_pi_v = calc_logprob(mu,log_std,actions)\n",
    "        assert logprob_pi_v.shape == batch_old_logprob_v.shape, \"logprob_pi_v.shape and batch_old_logprob_v have different shapes\"\n",
    "        ratio_v = tf.exp(logprob_pi_v - batch_old_logprob_v) # only positive values\n",
    "        surr_obj_v = tf.math.multiply(adv_batch,ratio_v)\n",
    "\n",
    "        #####\n",
    "        #print('OPTIMIZE NETWORK')\n",
    "        #print('Critic')\n",
    "        #print('value_v', value_v.shape)\n",
    "        #print('ref_batch', ref_batch.shape)\n",
    "        #print('loss_value_v', loss_value_v.shape)\n",
    "        #print('Actor')\n",
    "        #print('mu', mu.shape, 'log_std', log_std.shape)\n",
    "        #print('states', states.shape)\n",
    "        #print('actions', actions.shape)\n",
    "        #print('log_prob_pi', logprob_pi_v.shape)\n",
    "        #print('batch_old_logprob_v', batch_old_logprob_v.shape)\n",
    "        #print('ratio_v', ratio_v.shape)\n",
    "        #print('surr_obj_v',surr_obj_v.shape)\n",
    "        #print('adv_batch',adv_batch.shape)\n",
    "        #print('ref_batch',ref_batch.shape)\n",
    "        #print('_______________')\n",
    "        #####\n",
    "        \n",
    "        \n",
    "        clipped_surr_v = tf.math.multiply(adv_batch,tf.clip_by_value(ratio_v, 1.0 - agent.ppo_eps, 1 + agent.ppo_eps))\n",
    "        loss_policy_v = - tf.math.reduce_mean(tf.math.minimum(surr_obj_v,clipped_surr_v))\n",
    "        \n",
    "        #####\n",
    "        #print('surr_obj_v',surr_obj_v.shape)\n",
    "        #if loss_policy_v > 1.2:\n",
    "            #print('ratio_v',tf.math.reduce_mean(ratio_v))\n",
    "            #print('surr_obj_v',tf.math.reduce_mean(surr_obj_v))\n",
    "            #print('loss',loss_policy_v)\n",
    "        if tf.reduce_all(tf.math.is_nan(loss_policy_v)):\n",
    "            print('adv_batch',adv_batch)\n",
    "            print('ratio_v',ratio_v)\n",
    "            print('clipped_ratio_v',clipped_ratio_v)\n",
    "            print('logprob_pi',logprob_pi_v)\n",
    "            print('batch_old_logprob_v',batch_old_logprob_v)\n",
    "            print('mu',mu)\n",
    "            print('log_std',log_std)\n",
    "            print('actions',actions)\n",
    "        #####\n",
    "        \n",
    "    grads_crit = tape1.gradient(loss_value_v, agent.critic.trainable_variables)\n",
    "    grads_act = tape2.gradient(loss_policy_v, agent.actor.trainable_variables)\n",
    "    \n",
    "    grads_act, _ = tf.clip_by_global_norm(grads_act, 0.5)\n",
    "    assert tf.reduce_all(tf.math.is_nan(grads_crit[0])) == False, \"grads_crit have NaNs\"\n",
    "    assert tf.reduce_all(tf.math.is_nan(grads_act[0])) == False, \"grads_act have NaNs\"\n",
    "    \n",
    "    agent.critic_optimizer.apply_gradients(zip(grads_crit, agent.critic.trainable_variables))\n",
    "    agent.actor_optimizer.apply_gradients(zip(grads_act, agent.actor.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4EQwf8rNLu7I"
   },
   "outputs": [],
   "source": [
    " class Agent():\n",
    "    def __init__(self):\n",
    "        self.name = 'A2C_Agent'\n",
    "        \n",
    "    def agent_init(self):\n",
    "        self.name = 'A2C_Agent'\n",
    "        self.state_size = STATE_SIZE\n",
    "        self.output_size = OUTPUT_SIZE\n",
    "        self.test_iterations = TEST_ITERATIONS\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.critic_lr = ADAM_LR_CRITIC\n",
    "        self.actor_lr = ADAM_LR_ACTOR\n",
    "        self.gamma = GAMMA\n",
    "        self.gae_lambda = GAE_LAMBDA\n",
    "        self.tolerance = TOLERANCE\n",
    "        self.buffer_size = BUFFER_SIZE\n",
    "        self.timeout = TIMEOUT\n",
    "        self.ppo_eps = PPO_EPS\n",
    "        self.test_episode = TEST_EPISODE\n",
    "        self.epochs = TRAIN_EPOCHS\n",
    "        \n",
    "        # Generate NNs\n",
    "        self.actor = get_policy_network(self,self.state_size,self.output_size)\n",
    "        self.actor_optimizer = keras.optimizers.Adam(lr = self.actor_lr)\n",
    "        self.critic = get_value_network(self.state_size)\n",
    "        self.critic_optimizer = keras.optimizers.Adam(lr = self.critic_lr)\n",
    "        \n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "        \n",
    "        # Initialize buffers\n",
    "        self.buffer_old_logprob_v = []\n",
    "        self.adv_buffer = []\n",
    "        self.ref_buffer = []\n",
    "        self.optimize_buffer = []\n",
    "        self.distribution_buffer = []\n",
    "        self.extra_index = [] # Focused training\n",
    "        \n",
    "    def agent_start(self,state,test=False):\n",
    "        self.sum_rewards = 0\n",
    "        self.episode_steps = 0\n",
    "        self.total_turns = 0\n",
    "        self.total_time = 0\n",
    "        self.total_cost = 0\n",
    "        self.last_state = state\n",
    "        self.episode_buffer = []\n",
    "        mu,log_std = self.actor(self.last_state)\n",
    "        log_std = tf.clip_by_value(log_std, -9, 2)\n",
    "\n",
    "        #####\n",
    "        #print('AGENT_START')\n",
    "        #print('state shape',state.shape)\n",
    "        #print('state',state)\n",
    "        #print('last state', self.last_state.shape)\n",
    "        #print('mu shape',mu.shape)\n",
    "        #print('mu',mu)\n",
    "        #print('log_std shape',log_std.shape)\n",
    "        #print('log_std',log_std)\n",
    "        #####\n",
    "\n",
    "        self.last_action = get_actions(mu, log_std)\n",
    "\n",
    "        #####\n",
    "        #print('last action shape',self.last_action.shape)\n",
    "        #print('last action', self.last_action)\n",
    "        #print('_______________')\n",
    "        #####\n",
    "\n",
    "        if test:\n",
    "            self.last_action = mu\n",
    "        else:\n",
    "            self.distribution_buffer.append([mu.numpy(),log_std.numpy()])\n",
    "\n",
    "        return self.last_action\n",
    "        \n",
    "    def agent_step(self, reward, state,test=False):    \n",
    "        self.sum_rewards += reward\n",
    "        self.episode_steps += 1\n",
    "\n",
    "        mu,log_std = self.actor(state)\n",
    "        log_std = tf.clip_by_value(log_std, -9, 2)\n",
    "\n",
    "        if test:\n",
    "            actions = mu\n",
    "        else:\n",
    "            actions = get_actions(mu, log_std)       \n",
    "            # Append new experience to replay buffer\n",
    "            self.episode_buffer.append([self.last_state, self.last_action, reward, 0, state])\n",
    "            self.distribution_buffer.append([mu.numpy(),log_std.numpy()])\n",
    "\n",
    "        #####\n",
    "        #print('AGENT_STEP')\n",
    "        #print('state shape', state.shape)\n",
    "        #print('state',state)\n",
    "        #print('reward',reward)\n",
    "        #print('mu step shape', mu.shape, 'mu',mu)\n",
    "        #print('log_std_step shape', log_std.shape,'log_std',log_std)\n",
    "        #print('actions shape', actions.shape)\n",
    "        #print('actions',actions)\n",
    "        #print('episode_buffer',self.episode_buffer)\n",
    "        #print('distribution_buffer',self.distribution_buffer)\n",
    "        #print('_______________')\n",
    "        #####\n",
    "\n",
    "        # Update the last state and last action.\n",
    "        self.last_state = state\n",
    "        self.last_action = actions\n",
    "    \n",
    "    def agent_end(self, reward, state, test=False):\n",
    "        self.sum_rewards += reward\n",
    "        self.episode_steps += 1\n",
    "        \n",
    "        if not test:\n",
    "            # Set terminal state to an array of zeros\n",
    "            state = np.zeros_like(self.last_state)\n",
    "\n",
    "            # Append new experience to replay buffer\n",
    "            self.episode_buffer.append([self.last_state, self.last_action, reward, 1, state])\n",
    "\n",
    "            # We get the advantages and references of all this episode\n",
    "            adv_v, ref_v = get_adv_ref(self, self.episode_buffer)\n",
    "\n",
    "            len_opt_before = len(self.optimize_buffer) # Focused training   \n",
    "            \n",
    "            self.adv_buffer.extend(adv_v) \n",
    "            self.ref_buffer.extend(ref_v) \n",
    "            self.optimize_buffer.extend(self.episode_buffer) \n",
    "            \n",
    "            #####\n",
    "            #print('AGENT END')\n",
    "            #print('adv_v shape',np.shape(adv_v))\n",
    "            #print('adv_v:',adv_v)\n",
    "            #print('ref_v shape',np.shape(ref_v))\n",
    "            #print('ref_v:',ref_v)\n",
    "            #print('self.adv_buffer shape',np.shape(self.adv_buffer))\n",
    "            #print('self.adv_buffer',self.adv_buffer)\n",
    "            #print('self.ref_buffer shape',np.shape(self.ref_buffer))\n",
    "            #print('self.ref_buffer',self.ref_buffer)\n",
    "            #print('_______________')\n",
    "            #####\n",
    "            \n",
    "            # Focused training\n",
    "            if self.sum_rewards > 0:\n",
    "                len_opt_after = len(self.optimize_buffer) \n",
    "                index = np.arange(len_opt_before,len_opt_after)\n",
    "                index = index.tolist()\n",
    "                if self.sum_rewards>200:\n",
    "                    index = 4*index\n",
    "                elif self.sum_rewards > 100:\n",
    "                    index = 2*index\n",
    "                self.extra_index.extend(index)\n",
    "\n",
    "    def agent_message(self, message):\n",
    "        if message == \"get_sum_reward\":\n",
    "            return self.sum_rewards\n",
    "        else:\n",
    "            raise Exception(\"Unrecognized Message!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lVkLikqbLu7I"
   },
   "outputs": [],
   "source": [
    "def run_experiment(agent,num_episodes, max_count, load = False):\n",
    "    env = gym.make(ENV_NAME)\n",
    "    \n",
    "    agent_sum_reward = np.zeros((1,num_episodes))\n",
    "    agent_cost = np.zeros((1,num_episodes))\n",
    "    agent_time = np.zeros((1,num_episodes))\n",
    "    agent_turn = np.zeros((1,num_episodes))\n",
    "    agent.agent_init(agent)\n",
    "    \n",
    "    if load:\n",
    "        agent.critic.load_weights(\"G:/My Drive/JAXA/2020-2021/Transformer/weights/PPO_Lander_critic_\" + str(108) + \".h5\")\n",
    "        agent.actor.load_weights(\"G:/My Drive/JAXA/2020-2021/Transformer/weights/PPO_Lander_actor_\" + str(108) + \".h5\")\n",
    "        \n",
    "    for episode in tqdm(range(1,num_episodes + 1)):\n",
    "        run_episode(agent,env,test=False)\n",
    "        episode_reward = agent.agent_message(agent,'get_sum_reward')\n",
    "        agent_sum_reward[0,episode - 1] = episode_reward\n",
    "        #agent_cost[0,episode - 1] = agent.total_cost\n",
    "        #agent_time[0,episode - 1] = agent.total_time\n",
    "        #agent_turn[0,episode - 1] = agent.total_turns\n",
    "            \n",
    "        # Perform a test \n",
    "        if episode % agent.test_episode == 0:\n",
    "            print('Running test')\n",
    "            count = 0\n",
    "            sum_test_reward = 0\n",
    "            for t in range(1,agent.test_iterations):\n",
    "                run_episode(agent,env,test=True)\n",
    "                test_reward = agent.agent_message(agent,'get_sum_reward')\n",
    "                sum_test_reward += test_reward\n",
    "                if test_reward > 200:\n",
    "                    count += 1\n",
    "                    print('Test:', t, 'Test_Reward:', test_reward)\n",
    "                #print('Turns:', agent.total_turns, 'Time:', agent.total_time, 'Cost:', agent.total_cost)\n",
    "            print('Test finished with success ' + str(count) + ' out of ' + str(agent.test_iterations) + ' iterations.')\n",
    "            print('Test average reward is ' + str(sum_test_reward/agent.test_iterations))\n",
    "            if count>=max_count:\n",
    "                max_count = count\n",
    "                agent.critic.save_weights(\"G:/My Drive/JAXA/2020-2021/Transformer/weights/PPO_Lander_critic_\" + str(count) + \".h5\")\n",
    "                agent.actor.save_weights(\"G:/My Drive/JAXA/2020-2021/Transformer/weights/PPO_Lander_actor_\" + str(count) + \".h5\")\n",
    "        \n",
    "        run_episode(agent,env,test=False)\n",
    "        \n",
    "        if len(agent.optimize_buffer) > agent.buffer_size:\n",
    "            mu_v, log_std_v = map(list, zip(*agent.distribution_buffer))\n",
    "\n",
    "            #####\n",
    "            #print('TRAIN INSIDE EPISODE')\n",
    "            #print('mu before concat',np.shape(mu_v))\n",
    "            #print('mu',mu_v)\n",
    "            #print('log_std_v before concat', np.shape(log_std_v))\n",
    "            #print('log_std',log_std_v)\n",
    "            #print('len(agent.optimize_buffer)',len(agent.optimize_buffer))\n",
    "            #####\n",
    "\n",
    "            mu_v = np.concatenate(mu_v)\n",
    "            mu_v = tf.convert_to_tensor(mu_v, dtype=tf.float32)\n",
    "            log_std_v = np.concatenate(log_std_v)\n",
    "            log_std_v = tf.convert_to_tensor(log_std_v, dtype=tf.float32)\n",
    "\n",
    "            #####\n",
    "            #print('mu after concat',mu_v.shape)\n",
    "            #print('mu',mu_v)\n",
    "            #print('log_std_v after concat', log_std_v.shape)\n",
    "            #print('log_std',log_std_v)\n",
    "            #####\n",
    "\n",
    "            # Get states and actions\n",
    "            states, actions, rewards, terminals, next_states = map(list, zip(*agent.optimize_buffer))\n",
    "\n",
    "            actions = np.concatenate(actions)\n",
    "            states = np.concatenate(states)\n",
    "\n",
    "            #####\n",
    "            #print('actions after concat',actions.shape)\n",
    "            #print('actions',actions)\n",
    "            #print('states after concat', states.shape)\n",
    "            #print('states',states)\n",
    "            #####\n",
    "\n",
    "            old_logprob_v = calc_logprob(mu_v, log_std_v, actions)\n",
    "            adv_buffer = np.array(agent.adv_buffer, dtype = np.float32) # size (sth,)\n",
    "            adv_buffer = tf.expand_dims(adv_buffer,axis = 1).numpy()\n",
    "            ref_buffer = np.array(agent.ref_buffer, dtype = np.float32) # size (sth,)\n",
    "            ref_buffer = tf.expand_dims(ref_buffer,axis = 1).numpy()\n",
    "\n",
    "            #####\n",
    "            #print('old_logprob_v',old_logprob_v.shape)\n",
    "            #print('adv_buffer', adv_buffer.shape)\n",
    "            #print('ref_buffer', ref_buffer.shape)\n",
    "            #####\n",
    "\n",
    "            mean_adv = tf.math.reduce_mean(adv_buffer,axis =0, keepdims = True)\n",
    "            std_adv = tf.math.reduce_std(adv_buffer,axis =0, keepdims = True)\n",
    "            norm_adv = (adv_buffer - mean_adv) / (tf.clip_by_value(std_adv,1e-8,1e8)) # Corrected (this is the true normalization)\n",
    "            #norm_adv = tf.keras.utils.normalize(adv_buffer,axis = 0) # Corrected\n",
    "            \n",
    "            idxs = np.arange(len(states))\n",
    "            extra_idx = np.array(agent.extra_index) # Focused training\n",
    "            if not len(extra_idx) == None: # Focused training\n",
    "                idxs = np.append(idxs,extra_idx) # Focused training\n",
    "            np.random.shuffle(idxs) \n",
    "            idxs = idxs.astype(int) # Focused training\n",
    "            \n",
    "            #####\n",
    "            #print('norm_adv shape', norm_adv.shape)\n",
    "            #print('norm_adv', norm_adv)\n",
    "            #print('max of adv_v',tf.math.reduce_max(norm_adv))\n",
    "            #print('min of adv_v',tf.math.reduce_min (norm_adv))\n",
    "            #print('shape idx',idxs.shape)\n",
    "            #print(idxs)\n",
    "            #####\n",
    "            \n",
    "            for epoch in range(agent.epochs):\n",
    "                #num_batches = int(math.floor(len(states)/agent.batch_size))\n",
    "                num_batches = int(math.floor(len(idxs)/agent.batch_size)) # Focused training\n",
    "\n",
    "                #####\n",
    "                #print('NUM BATCHES', num_batches)\n",
    "                #####\n",
    "\n",
    "                for batch in range(num_batches):\n",
    "                    start_num = batch*agent.batch_size\n",
    "                    end_num = start_num + agent.batch_size\n",
    "\n",
    "                    #####\n",
    "                    #print('len(states)',len(states))\n",
    "                    #print('shape states',states.shape)\n",
    "                    #print('slice idx',idxs[start_num:end_num])\n",
    "                    #####\n",
    "\n",
    "                    #states_batch = states[start_num:end_num]\n",
    "                    states_batch = np.array([states[idx] for idx in idxs[start_num:end_num]])\n",
    "                    actions_batch = np.array([actions[idx] for idx in idxs[start_num:end_num]])\n",
    "                    adv_batch = np.array([norm_adv[idx] for idx in idxs[start_num:end_num]]) \n",
    "                    ref_batch = np.array([ref_buffer[idx] for idx in idxs[start_num:end_num]]) \n",
    "                    old_logprob_v_batch = np.array([old_logprob_v[idx] for idx in idxs[start_num:end_num]])\n",
    "\n",
    "                    #####\n",
    "                    #print('BATCHES')\n",
    "                    #print(' states_batch', states_batch.shape)\n",
    "                    #print('actions_batch', actions_batch.shape)\n",
    "                    #print('adv_batch', adv_batch.shape)\n",
    "                    #print('ref_batch', ref_batch.shape)\n",
    "                    #print('old_logprob_v_batch', old_logprob_v_batch.shape)\n",
    "                    #print('adv_batch',adv_batch)\n",
    "                    #####\n",
    "\n",
    "                    optimize_network(agent,states_batch,actions_batch,adv_batch,ref_batch,old_logprob_v_batch)\n",
    "                    \n",
    "            #####\n",
    "            #if episode%100 == 0:\n",
    "                #print('mu_v', mu_v)\n",
    "                #print('log_std_v',log_std_v)\n",
    "            #####        \n",
    "                    \n",
    "            # restart all lists\n",
    "            del agent.buffer_old_logprob_v[:]\n",
    "            del agent.adv_buffer[:]\n",
    "            del agent.ref_buffer[:]\n",
    "            del agent.optimize_buffer[:]\n",
    "            del agent.distribution_buffer[:]\n",
    "            del agent.extra_index[:]\n",
    "\n",
    "        if episode%10 == 0 or episode == 1:\n",
    "            print('Episodes:', episode, 'Episodic_Reward:', episode_reward)\n",
    "            #print('Turns:', agent.total_turns, 'Time:', agent.total_time, 'Cost:', agent.total_cost)\n",
    "            \n",
    "        if episode%50 == 0 or episode == 1:\n",
    "            env.render()\n",
    "\n",
    "        if episode_reward > 200:\n",
    "          print('Success in episode ' + str(episode) + ' with a reward of ' + str(episode_reward))\n",
    "        elif episode_reward > 100:\n",
    "          print('Looking good in ' + str(episode) + ' with a reward of ' + str(episode_reward))\n",
    "        elif episode_reward > 0:\n",
    "          print('Getting somewhere in ' + str(episode) + ' with a reward of ' + str(episode_reward))\n",
    "        \n",
    "    save_name = \"{}\".format(agent.name) \n",
    "    if not os.path.exists('results'):\n",
    "        os.makedirs('results')\n",
    "    np.save(\"results/sum_reward_{}\".format(save_name), agent_sum_reward)\n",
    "    shutil.make_archive('results', 'zip', 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1NwLepV9Lu7J"
   },
   "outputs": [],
   "source": [
    "def get_objective_attitude(min_ang, max_ang):\n",
    "    euler_1 = (min_ang + rd.random()*(max_ang - min_ang)) * np.pi/180\n",
    "    euler_2 = (min_ang + rd.random()*(max_ang - min_ang)) * np.pi/180\n",
    "    euler_3 = (min_ang + rd.random()*(max_ang - min_ang)) * np.pi/180\n",
    "    '''\n",
    "    if rd.random() < 0.33:\n",
    "        euler_1 = 0.0\n",
    "    elif rd.random() > 0.66:\n",
    "        euler_1 = 0.0\n",
    "        euler_2 = 0.0\n",
    "    '''\n",
    "    initial_att = np.array([euler_1,euler_2,euler_3])\n",
    "    \n",
    "    # np.random.shuffle(initial_att)      \n",
    "    objective_attitude = initial_att\n",
    "    return objective_attitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jU-wnmy6Lu7J"
   },
   "outputs": [],
   "source": [
    "def run_episode(agent,env,test=False):\n",
    "    done = False\n",
    "    s = env.reset()\n",
    "\n",
    "    # First the objective attitude is given in the form of Euler y-x-z in rad\n",
    "    #objective_attitude = get_objective_attitude(MIN_ANG, MAX_ANG)\n",
    "    # The initial attitude of the sc is always zero\n",
    "    #initial_attitude = np.array([0,0,0])    \n",
    "    # Initial state (1,6)\n",
    "    #last_state = np.array([np.append(objective_attitude,np.append(initial_attitude,diff))])\n",
    "    last_state = np.zeros((1,agent.state_size[0]))\n",
    "    # Action (1,12)\n",
    "    last_action = agent.agent_start(agent,last_state,test)\n",
    "    # Let's start the real episode\n",
    "    while (done == False):\n",
    "        # We get the next state from the environment, as well as the reward and if terminal\n",
    "        #state, reward, done = environment(agent)\n",
    "        state, reward, done, _ = env.step(tf.squeeze(agent.last_action).numpy())\n",
    "        state = np.array([state])#tf.expand_dims(state, axis=0).numpy().tolist()\n",
    "        if done:\n",
    "            agent.agent_end(agent,reward, state,test)\n",
    "        else:\n",
    "            agent.agent_step(agent, reward, state,test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1pXsvyP8Lu7J"
   },
   "outputs": [],
   "source": [
    "STATE_SIZE = (8,)\n",
    "OUTPUT_SIZE = (2,)\n",
    "TEST_ITERATIONS = 100\n",
    "BATCH_SIZE = 64\n",
    "ADAM_LR_CRITIC = 5e-4\n",
    "ADAM_LR_ACTOR = 5e-5\n",
    "GAMMA = 0.99\n",
    "GAE_LAMBDA = 0.95\n",
    "TOLERANCE = None\n",
    "BUFFER_SIZE = 2048\n",
    "TIMEOUT = None\n",
    "PPO_EPS = 0.2\n",
    "TEST_EPISODE = 50\n",
    "TRAIN_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBaVuPnOLu7J",
    "outputId": "22f1bcc8-83e1-4b1b-c7ac-c3372615ffab",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 1 Episodic_Reward: -49.230032500672024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/3000 [00:08<1:07:56,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 10 Episodic_Reward: -393.73575772356884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/3000 [00:16<49:14,  1.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 20 Episodic_Reward: -169.5211486105952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30/3000 [00:25<51:16,  1.04s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 30 Episodic_Reward: -371.8780124993341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 40/3000 [00:33<39:27,  1.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 40 Episodic_Reward: -290.4919907712265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 49/3000 [00:40<46:24,  1.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test\n",
      "Test finished with success 0 out of 100 iterations.\n",
      "Test average reward is -873.716769676374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 50/3000 [00:54<4:01:47,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 50 Episodic_Reward: -260.4916592319884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 60/3000 [01:02<35:53,  1.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 60 Episodic_Reward: -557.9632199298376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 70/3000 [01:10<34:43,  1.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 70 Episodic_Reward: -292.8908391218957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 80/3000 [01:18<33:55,  1.43it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 80 Episodic_Reward: -629.6652223702918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 90/3000 [01:26<40:55,  1.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 90 Episodic_Reward: -417.8355075380188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 99/3000 [01:33<49:12,  1.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test\n",
      "Test finished with success 0 out of 100 iterations.\n",
      "Test average reward is -681.5657646521853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 100/3000 [01:45<3:31:02,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 100 Episodic_Reward: -653.5609182778177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 110/3000 [01:53<35:58,  1.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 110 Episodic_Reward: -256.3484059582445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 120/3000 [02:01<29:38,  1.62it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 120 Episodic_Reward: -285.00187395319324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 130/3000 [02:10<26:58,  1.77it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 130 Episodic_Reward: -179.78418034927466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 140/3000 [02:19<25:07,  1.90it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 140 Episodic_Reward: -393.2738528394987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 149/3000 [02:27<26:22,  1.80it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test\n",
      "Test finished with success 0 out of 100 iterations.\n",
      "Test average reward is -595.5795399429273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 150/3000 [02:40<3:22:08,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 150 Episodic_Reward: -450.0929062430653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 160/3000 [02:49<36:55,  1.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 160 Episodic_Reward: -123.91433204577265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 170/3000 [03:02<1:19:53,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 170 Episodic_Reward: -130.55623754442863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 180/3000 [03:07<20:35,  2.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 180 Episodic_Reward: -345.97564491751757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 190/3000 [03:14<19:25,  2.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 190 Episodic_Reward: -88.66977758652665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 199/3000 [03:22<26:15,  1.78it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test\n",
      "Test finished with success 0 out of 100 iterations.\n",
      "Test average reward is -424.91564646622743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 200/3000 [03:44<5:24:21,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 200 Episodic_Reward: -569.2995835276454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 210/3000 [03:51<1:16:12,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 210 Episodic_Reward: -32.113351908730536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 220/3000 [03:55<19:27,  2.38it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 220 Episodic_Reward: -657.1502301895958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 230/3000 [04:03<21:30,  2.15it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 230 Episodic_Reward: -314.1153713901574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 240/3000 [04:11<20:09,  2.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 240 Episodic_Reward: -134.12006314064382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 249/3000 [04:19<27:55,  1.64it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test\n",
      "Test finished with success 0 out of 100 iterations.\n",
      "Test average reward is -230.20643107487402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 250/3000 [04:31<3:04:54,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 250 Episodic_Reward: -98.62782670036246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 260/3000 [04:39<26:24,  1.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 260 Episodic_Reward: -93.65470015070582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 270/3000 [04:48<27:42,  1.64it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 270 Episodic_Reward: -87.29429570684158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 280/3000 [04:56<25:30,  1.78it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 280 Episodic_Reward: -98.42354124288646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 290/3000 [05:08<1:06:54,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 290 Episodic_Reward: -400.73409157848573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 299/3000 [05:16<1:10:14,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test\n",
      "Test: 44 Test_Reward: 200.1043261849549\n",
      "Test finished with success 1 out of 100 iterations.\n",
      "Test average reward is -224.25109808454857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 300/3000 [05:30<3:55:59,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 300 Episodic_Reward: -159.84229163161527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 310/3000 [05:39<47:00,  1.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 310 Episodic_Reward: -134.04915725626554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 320/3000 [05:49<43:26,  1.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 320 Episodic_Reward: -466.2466652061688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 328/3000 [06:00<45:25,  1.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 328 with a reward of 2.4328201033009407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 330/3000 [06:07<1:29:47,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 330 Episodic_Reward: -59.305997806255675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 336/3000 [06:14<1:09:29,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 336 with a reward of 11.721046882849961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 340/3000 [06:16<33:43,  1.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 340 Episodic_Reward: -48.86635200796444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 349/3000 [06:34<1:26:10,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test\n",
      "Test finished with success 0 out of 100 iterations.\n",
      "Test average reward is -393.5130714777821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 350/3000 [06:54<5:22:40,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 350 Episodic_Reward: -15.259345655633709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 351/3000 [06:54<3:51:38,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 351 with a reward of 6.373358915472835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 360/3000 [07:10<1:10:35,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 360 Episodic_Reward: -16.466392904974725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 370/3000 [07:20<32:26,  1.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 370 Episodic_Reward: -178.47303972052592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 378/3000 [07:35<1:13:36,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 378 with a reward of 11.648623641213447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 380/3000 [07:37<53:51,  1.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 380 Episodic_Reward: -113.05821413146386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 386/3000 [07:46<50:38,  1.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 386 with a reward of 11.676937081110182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 389/3000 [07:51<56:06,  1.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 389 with a reward of 7.646505682028149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 390/3000 [07:53<58:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 390 Episodic_Reward: -416.2418860210221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 399/3000 [08:10<1:03:11,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test\n",
      "Test finished with success 0 out of 100 iterations.\n",
      "Test average reward is -364.7691674296831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 400/3000 [08:31<5:13:29,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 400 Episodic_Reward: -21.453953225217788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 402/3000 [08:32<2:48:55,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 402 with a reward of 38.452842226674534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 404/3000 [08:38<2:16:41,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 404 with a reward of 32.26266872382499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 410/3000 [08:51<1:44:43,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 410 Episodic_Reward: -174.51160872204437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 420/3000 [09:18<2:35:29,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 420 Episodic_Reward: -75.15893817113255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 428/3000 [09:53<4:16:21,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 428 with a reward of 0.9250987593005675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 430/3000 [09:54<2:25:00,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 430 Episodic_Reward: -78.87461068074639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 437/3000 [10:34<4:13:28,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 437 with a reward of 35.62367744565043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 440/3000 [10:44<3:03:42,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 440 Episodic_Reward: 22.359648410099012\n",
      "Getting somewhere in 440 with a reward of 22.359648410099012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 444/3000 [11:06<3:41:16,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 444 with a reward of 59.13705034529917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 446/3000 [11:19<4:38:59,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 446 with a reward of 14.127583861253893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 449/3000 [11:44<5:05:13,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test\n",
      "Test finished with success 0 out of 100 iterations.\n",
      "Test average reward is -448.87006309425067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 450/3000 [12:21<11:33:13, 16.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 450 Episodic_Reward: -280.5150264550041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 451/3000 [12:22<8:15:57, 11.67s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 451 with a reward of 2.1562113528786853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 457/3000 [13:03<4:10:35,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 457 with a reward of 17.79089643458539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 460/3000 [13:23<4:30:39,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 460 Episodic_Reward: -25.371397633761617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 463/3000 [13:37<3:29:24,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 463 with a reward of 14.596073469735103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 465/3000 [13:52<4:52:03,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 465 with a reward of 35.19873185414545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 467/3000 [14:18<7:22:34, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 467 with a reward of 18.468881196984896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 470/3000 [14:40<5:51:59,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 470 Episodic_Reward: -74.66989468993751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 473/3000 [15:11<6:49:33,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 473 with a reward of 35.20582918724143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 475/3000 [15:36<8:14:53, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 475 with a reward of 14.945858107160376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 476/3000 [15:43<7:08:40, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 476 with a reward of 57.55708164744824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 477/3000 [16:03<9:19:03, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 477 with a reward of 78.05384649118747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 479/3000 [16:27<9:13:02, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 479 with a reward of 120.42914851538083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 480/3000 [16:28<6:36:41,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 480 Episodic_Reward: -31.271209553034083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 481/3000 [16:46<8:27:19, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 481 with a reward of 101.03933838561441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 482/3000 [16:53<7:25:55, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 482 with a reward of 132.01001397282988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 483/3000 [17:16<10:02:37, 14.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 483 with a reward of 134.7897835263447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 484/3000 [17:24<8:41:45, 12.44s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 484 with a reward of 98.79460636809237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 485/3000 [17:47<10:58:17, 15.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 485 with a reward of 147.4242060087109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 486/3000 [17:50<8:18:19, 11.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 486 with a reward of 191.19374596430418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 487/3000 [18:05<8:51:40, 12.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 487 with a reward of 107.37238272691592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 489/3000 [18:30<9:24:15, 13.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 489 with a reward of 105.42393666678689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 490/3000 [18:32<7:07:06, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 490 Episodic_Reward: 236.02528386361357\n",
      "Success in episode 490 with a reward of 236.02528386361357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 491/3000 [18:55<9:41:30, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 491 with a reward of 193.86689524107334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 492/3000 [18:59<7:44:15, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 492 with a reward of 34.824139453234686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 493/3000 [19:13<8:12:09, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 493 with a reward of 213.48544186384768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 494/3000 [19:15<6:07:08,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 494 with a reward of 256.5430390514772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 495/3000 [19:17<4:44:34,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 495 with a reward of 199.66645262706396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 496/3000 [19:35<7:04:47, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 496 with a reward of 262.7194932055012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 497/3000 [19:37<5:17:23,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 497 with a reward of 222.5542370222244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 498/3000 [19:39<4:08:46,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 498 with a reward of 257.598067097578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 499/3000 [19:57<6:45:19,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 499 with a reward of 226.97347118335864\n",
      "Running test\n",
      "Test finished with success 0 out of 100 iterations.\n",
      "Test average reward is -96.72802467683137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 500/3000 [24:58<67:28:27, 97.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 500 Episodic_Reward: 282.3806908143275\n",
      "Success in episode 500 with a reward of 282.3806908143275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 501/3000 [25:01<47:51:27, 68.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 501 with a reward of 224.30906799481977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 502/3000 [25:27<38:54:45, 56.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 502 with a reward of 209.47254161252044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 503/3000 [25:30<27:40:48, 39.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 503 with a reward of 218.04018386680343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 504/3000 [25:32<19:45:45, 28.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 504 with a reward of 242.44160865864984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 505/3000 [25:51<17:47:28, 25.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 505 with a reward of 240.14020819145372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 506/3000 [25:52<12:47:44, 18.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 506 with a reward of 237.20757940481877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 507/3000 [25:54<9:15:45, 13.38s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 507 with a reward of 263.8680259362055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 508/3000 [26:15<10:59:43, 15.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 508 with a reward of 150.83058315892288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 509/3000 [26:18<8:11:10, 11.83s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 509 with a reward of 268.55137098821626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 510/3000 [26:20<6:08:35,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 510 Episodic_Reward: -378.16122883117777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 511/3000 [26:40<8:33:42, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 511 with a reward of 220.76998916552253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 512/3000 [26:42<6:13:06,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 512 with a reward of 235.97916395872505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 514/3000 [26:44<3:31:36,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 514 with a reward of 245.46353961104452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 515/3000 [27:05<6:42:37,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 515 with a reward of 221.25025036491775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 516/3000 [27:06<5:01:01,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 516 with a reward of 232.81394963234106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 518/3000 [27:09<3:00:27,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 518 with a reward of 184.86945184283832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 519/3000 [27:30<6:16:20,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 519 with a reward of 264.1880491418606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 520/3000 [27:32<4:48:00,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 520 Episodic_Reward: -15.510073744328167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 521/3000 [27:33<3:34:53,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 521 with a reward of 34.28116806393328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 522/3000 [27:34<2:49:41,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 522 with a reward of 267.61100600364085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 526/3000 [28:03<4:27:15,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 526 with a reward of 246.93395749053735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 527/3000 [28:05<3:25:07,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 527 with a reward of 267.568250828626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 528/3000 [28:06<2:44:06,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 528 with a reward of 247.35330090243698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 529/3000 [28:08<2:10:50,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 529 with a reward of 270.88866483033394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 530/3000 [28:26<5:13:08,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 530 Episodic_Reward: 278.0125086400284\n",
      "Success in episode 530 with a reward of 278.0125086400284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 531/3000 [28:27<3:55:10,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 531 with a reward of 8.440259614785361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 532/3000 [28:28<2:58:19,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 532 with a reward of 267.4394276544593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 533/3000 [28:29<2:20:12,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 533 with a reward of 41.135060323374205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 534/3000 [28:46<5:04:39,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 534 with a reward of 246.1456182802551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 535/3000 [28:48<3:50:00,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 535 with a reward of 257.5065880654324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 536/3000 [28:50<3:13:25,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 536 with a reward of 276.8932173535148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 537/3000 [29:07<5:41:35,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 537 with a reward of 260.6405926996159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 538/3000 [29:08<4:13:10,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 538 with a reward of 248.93382483586225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 539/3000 [29:09<3:09:56,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 539 with a reward of 265.42352391827296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 540/3000 [29:10<2:29:09,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 540 Episodic_Reward: 275.78809237650825\n",
      "Success in episode 540 with a reward of 275.78809237650825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 541/3000 [29:28<5:26:03,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 541 with a reward of 226.10526607650547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 542/3000 [29:30<4:04:20,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 542 with a reward of 268.2783294905608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 543/3000 [29:31<3:05:24,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 543 with a reward of 300.1267724971206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 545/3000 [29:52<5:44:12,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 545 with a reward of 286.8055588836091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 546/3000 [29:53<4:13:12,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 546 with a reward of 236.728850658105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 547/3000 [29:54<3:15:21,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 547 with a reward of 294.15691033569294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 548/3000 [29:56<2:34:39,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 548 with a reward of 285.3518124044417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 549/3000 [30:17<6:00:57,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 549 with a reward of 299.6105486428929\n",
      "Running test\n",
      "Test: 1 Test_Reward: 231.15213520611263\n",
      "Test: 2 Test_Reward: 212.04951743072587\n",
      "Test: 3 Test_Reward: 260.73214823786805\n",
      "Test: 5 Test_Reward: 225.28405885903322\n",
      "Test: 10 Test_Reward: 237.79635393795166\n",
      "Test: 11 Test_Reward: 266.57507310276367\n",
      "Test: 12 Test_Reward: 231.80813550599748\n",
      "Test: 14 Test_Reward: 239.28530856831347\n",
      "Test: 16 Test_Reward: 250.35750002430132\n",
      "Test: 17 Test_Reward: 228.38663243598958\n",
      "Test: 18 Test_Reward: 279.6468785851551\n",
      "Test: 20 Test_Reward: 266.3428636004782\n",
      "Test: 21 Test_Reward: 213.83922510269184\n",
      "Test: 23 Test_Reward: 300.4186875198236\n",
      "Test: 25 Test_Reward: 248.23109206955658\n",
      "Test: 26 Test_Reward: 261.4359062909871\n",
      "Test: 27 Test_Reward: 273.45842875639715\n",
      "Test: 28 Test_Reward: 230.31140855425488\n",
      "Test: 29 Test_Reward: 228.60323408458405\n",
      "Test: 30 Test_Reward: 208.27480295182943\n",
      "Test: 33 Test_Reward: 215.30005966055006\n",
      "Test: 34 Test_Reward: 227.8335778672869\n",
      "Test: 35 Test_Reward: 236.13370971316374\n",
      "Test: 37 Test_Reward: 200.09551485671113\n",
      "Test: 38 Test_Reward: 207.15290319954943\n",
      "Test: 39 Test_Reward: 249.16399952535048\n",
      "Test: 40 Test_Reward: 239.9059004532876\n",
      "Test: 41 Test_Reward: 266.20811028935555\n",
      "Test: 43 Test_Reward: 280.11875559309703\n",
      "Test: 44 Test_Reward: 255.03983300822722\n",
      "Test: 45 Test_Reward: 243.4470029746134\n",
      "Test: 46 Test_Reward: 265.10693610302206\n",
      "Test: 47 Test_Reward: 269.2210361385603\n",
      "Test: 48 Test_Reward: 245.13305165202055\n",
      "Test: 50 Test_Reward: 248.68183418295197\n",
      "Test: 51 Test_Reward: 206.6917731528472\n",
      "Test: 52 Test_Reward: 237.10478115974522\n",
      "Test: 53 Test_Reward: 283.7367780597607\n",
      "Test: 54 Test_Reward: 206.01013153176723\n",
      "Test: 55 Test_Reward: 256.3090740844047\n",
      "Test: 56 Test_Reward: 236.7314826510464\n",
      "Test: 57 Test_Reward: 243.68578393621038\n",
      "Test: 58 Test_Reward: 241.127169632015\n",
      "Test: 59 Test_Reward: 268.86690637721796\n",
      "Test: 60 Test_Reward: 231.92757074844542\n",
      "Test: 61 Test_Reward: 219.16006826980964\n",
      "Test: 63 Test_Reward: 265.8786448502201\n",
      "Test: 64 Test_Reward: 238.01128914221135\n",
      "Test: 65 Test_Reward: 271.8218045568369\n",
      "Test: 66 Test_Reward: 211.43558213609327\n",
      "Test: 67 Test_Reward: 244.21269388119777\n",
      "Test: 68 Test_Reward: 230.2098165934622\n",
      "Test: 70 Test_Reward: 271.7606090030369\n",
      "Test: 71 Test_Reward: 279.92595733122255\n",
      "Test: 72 Test_Reward: 217.1029608263671\n",
      "Test: 73 Test_Reward: 235.76838881343997\n",
      "Test: 74 Test_Reward: 252.7231576690531\n",
      "Test: 75 Test_Reward: 258.1631825702286\n",
      "Test: 76 Test_Reward: 231.44179120019476\n",
      "Test: 78 Test_Reward: 259.8239329043405\n",
      "Test: 79 Test_Reward: 293.7386823222023\n",
      "Test: 81 Test_Reward: 279.1244982973408\n",
      "Test: 82 Test_Reward: 239.13489274285445\n",
      "Test: 84 Test_Reward: 259.6019749397499\n",
      "Test: 85 Test_Reward: 273.25415576914713\n",
      "Test: 87 Test_Reward: 215.26201016065295\n",
      "Test: 88 Test_Reward: 231.8649462543133\n",
      "Test: 89 Test_Reward: 249.79195904399577\n",
      "Test: 90 Test_Reward: 231.076237026196\n",
      "Test: 91 Test_Reward: 233.33129636482298\n",
      "Test: 93 Test_Reward: 253.64318267189935\n",
      "Test: 94 Test_Reward: 245.35971336150791\n",
      "Test: 95 Test_Reward: 205.6209841992768\n",
      "Test: 97 Test_Reward: 292.08323179445125\n",
      "Test: 99 Test_Reward: 202.26748485612347\n",
      "Test finished with success 75 out of 100 iterations.\n",
      "Test average reward is 201.16638820554996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 550/3000 [31:50<23:14:54, 34.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 550 Episodic_Reward: 264.6080769593706\n",
      "Success in episode 550 with a reward of 264.6080769593706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 551/3000 [31:51<16:30:08, 24.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 551 with a reward of 231.81030275127324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 552/3000 [31:53<11:53:40, 17.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 552 with a reward of 294.5423307420052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 553/3000 [32:12<12:10:46, 17.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 553 with a reward of 263.36228212364995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 554/3000 [32:13<8:43:36, 12.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 554 with a reward of 261.6403188935285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 555/3000 [32:14<6:23:45,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 555 with a reward of 287.4012745166409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 556/3000 [32:15<4:42:28,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 556 with a reward of 280.4131421607594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 557/3000 [32:32<6:49:33, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 557 with a reward of 7.840477960712221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 558/3000 [32:34<5:04:30,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 558 with a reward of 293.11289035940297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 559/3000 [32:35<3:46:32,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 559 with a reward of 229.19755142995524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 560/3000 [32:36<2:49:55,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 560 Episodic_Reward: 224.3347326584579\n",
      "Success in episode 560 with a reward of 224.3347326584579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 561/3000 [32:55<5:46:29,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 561 with a reward of 231.22332832341039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 562/3000 [32:56<4:19:11,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 562 with a reward of 250.71372708956363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 563/3000 [32:57<3:15:54,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 563 with a reward of 216.00612857568865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 564/3000 [32:59<2:33:34,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 564 with a reward of 246.79450527869977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 565/3000 [33:21<6:16:58,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 565 with a reward of 212.92332988721347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 566/3000 [33:22<4:41:24,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 566 with a reward of 221.49664472194644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 567/3000 [33:24<3:44:29,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 567 with a reward of 267.1568560780669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 568/3000 [33:45<6:42:16,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 568 with a reward of 279.43638406261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 569/3000 [33:46<4:56:33,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 569 with a reward of 32.23835460675741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 570/3000 [33:47<3:43:54,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 570 Episodic_Reward: 278.14073935812075\n",
      "Success in episode 570 with a reward of 278.14073935812075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 571/3000 [33:48<2:52:17,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 571 with a reward of 237.75189043581267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 573/3000 [34:11<4:38:18,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 573 with a reward of 264.1016225668285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 574/3000 [34:12<3:32:38,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 574 with a reward of 242.60840446627645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 575/3000 [34:14<2:44:17,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 575 with a reward of 288.06539343790416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 576/3000 [34:34<5:59:12,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 576 with a reward of 276.3427323766617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 578/3000 [34:38<3:38:23,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 578 with a reward of 248.36109673486214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 579/3000 [34:49<4:42:17,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 579 with a reward of 240.84005313408494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 580/3000 [34:50<3:33:44,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 580 Episodic_Reward: 282.28905403247063\n",
      "Success in episode 580 with a reward of 282.28905403247063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 581/3000 [34:52<2:46:19,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 581 with a reward of 277.82585811366266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 582/3000 [34:53<2:11:02,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 582 with a reward of 258.02503851413815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 583/3000 [35:17<6:24:24,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 583 with a reward of 262.3649923877911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 584/3000 [35:18<4:40:00,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 584 with a reward of 264.7096308975491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 585/3000 [35:19<3:30:18,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 585 with a reward of 229.88565799269696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 586/3000 [35:20<2:40:49,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 586 with a reward of 291.67147932658224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 587/3000 [35:21<2:05:09,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 587 with a reward of 230.70298780026855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 588/3000 [35:45<6:07:15,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 588 with a reward of 285.35039288241444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 589/3000 [35:46<4:36:53,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 589 with a reward of 260.39759844856155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 590/3000 [35:47<3:26:19,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 590 Episodic_Reward: 275.0833975610732\n",
      "Success in episode 590 with a reward of 275.0833975610732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 591/3000 [35:49<2:44:08,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 591 with a reward of 243.4871015188324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 592/3000 [36:08<5:46:53,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 592 with a reward of 263.5006702928962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 593/3000 [36:11<4:35:33,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 593 with a reward of 238.90632866661682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 595/3000 [36:27<5:15:51,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 595 with a reward of 242.137884686409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 596/3000 [36:28<3:54:55,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 596 with a reward of 251.02515043159158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 597/3000 [36:29<2:58:00,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 597 with a reward of 261.40669425584315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 598/3000 [36:31<2:24:59,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 598 with a reward of 277.07302732116784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 599/3000 [36:47<5:01:28,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 599 with a reward of 253.22018071963993\n",
      "Running test\n",
      "Test: 1 Test_Reward: 274.11599711389306\n",
      "Test: 2 Test_Reward: 288.89793595091123\n",
      "Test: 4 Test_Reward: 239.55239219173743\n",
      "Test: 5 Test_Reward: 270.1576641236259\n",
      "Test: 6 Test_Reward: 214.34011396408886\n",
      "Test: 7 Test_Reward: 232.06358095320553\n",
      "Test: 8 Test_Reward: 247.79798568964992\n",
      "Test: 11 Test_Reward: 263.9410789933288\n",
      "Test: 12 Test_Reward: 253.60354324714947\n",
      "Test: 14 Test_Reward: 249.10741032527838\n",
      "Test: 15 Test_Reward: 295.946721102664\n",
      "Test: 16 Test_Reward: 294.45623916415104\n",
      "Test: 17 Test_Reward: 284.4574130754103\n",
      "Test: 18 Test_Reward: 218.7067073389087\n",
      "Test: 19 Test_Reward: 282.54018574792786\n",
      "Test: 20 Test_Reward: 266.86106421695865\n",
      "Test: 21 Test_Reward: 231.2596731682846\n",
      "Test: 22 Test_Reward: 201.67568295010764\n",
      "Test: 23 Test_Reward: 201.25073156592896\n",
      "Test: 24 Test_Reward: 242.26727158914585\n",
      "Test: 25 Test_Reward: 254.87159469283733\n",
      "Test: 26 Test_Reward: 311.56873459596443\n",
      "Test: 27 Test_Reward: 269.8537442475101\n",
      "Test: 28 Test_Reward: 284.935713487445\n",
      "Test: 29 Test_Reward: 283.14610250429814\n",
      "Test: 30 Test_Reward: 285.0170048308569\n",
      "Test: 32 Test_Reward: 286.8376854613333\n",
      "Test: 33 Test_Reward: 229.36234148562977\n",
      "Test: 35 Test_Reward: 226.8780598421109\n",
      "Test: 36 Test_Reward: 224.61288474857434\n",
      "Test: 37 Test_Reward: 284.6676893534185\n",
      "Test: 38 Test_Reward: 260.7129336485033\n",
      "Test: 39 Test_Reward: 260.3872349360541\n",
      "Test: 40 Test_Reward: 235.89755766732972\n",
      "Test: 41 Test_Reward: 258.1552611768071\n",
      "Test: 42 Test_Reward: 250.08090754945488\n",
      "Test: 43 Test_Reward: 267.5575721635788\n",
      "Test: 44 Test_Reward: 296.82368059975204\n",
      "Test: 45 Test_Reward: 277.5530526091003\n",
      "Test: 46 Test_Reward: 262.7032659354162\n",
      "Test: 47 Test_Reward: 273.7261201445126\n",
      "Test: 48 Test_Reward: 219.0259251121085\n",
      "Test: 49 Test_Reward: 280.28367360635934\n",
      "Test: 50 Test_Reward: 233.7070837428599\n",
      "Test: 51 Test_Reward: 277.406194884629\n",
      "Test: 54 Test_Reward: 219.91068908738274\n",
      "Test: 55 Test_Reward: 229.85547896701297\n",
      "Test: 56 Test_Reward: 270.7039307628353\n",
      "Test: 58 Test_Reward: 282.20263479948426\n",
      "Test: 59 Test_Reward: 207.59025292046866\n",
      "Test: 60 Test_Reward: 222.16656127011652\n",
      "Test: 61 Test_Reward: 229.66515700917586\n",
      "Test: 62 Test_Reward: 249.08337190700598\n",
      "Test: 63 Test_Reward: 272.12653227140936\n",
      "Test: 64 Test_Reward: 278.45620104166125\n",
      "Test: 65 Test_Reward: 264.35054512994304\n",
      "Test: 66 Test_Reward: 211.80654173587934\n",
      "Test: 67 Test_Reward: 232.99764606077858\n",
      "Test: 68 Test_Reward: 264.48209317950835\n",
      "Test: 69 Test_Reward: 298.2755949237152\n",
      "Test: 70 Test_Reward: 273.2081207204109\n",
      "Test: 71 Test_Reward: 260.95080466904733\n",
      "Test: 73 Test_Reward: 222.85651523537763\n",
      "Test: 74 Test_Reward: 245.19214866267137\n",
      "Test: 75 Test_Reward: 249.3234209212056\n",
      "Test: 76 Test_Reward: 225.28912603286346\n",
      "Test: 78 Test_Reward: 295.20323837952355\n",
      "Test: 79 Test_Reward: 277.31907990686886\n",
      "Test: 80 Test_Reward: 262.01259106045165\n",
      "Test: 81 Test_Reward: 246.8164599066864\n",
      "Test: 82 Test_Reward: 236.80192220691941\n",
      "Test: 83 Test_Reward: 224.15768566012548\n",
      "Test: 84 Test_Reward: 210.52515247921173\n",
      "Test: 85 Test_Reward: 253.38409745252625\n",
      "Test: 86 Test_Reward: 264.47037121611413\n",
      "Test: 87 Test_Reward: 293.831783174315\n",
      "Test: 88 Test_Reward: 241.69340535192399\n",
      "Test: 89 Test_Reward: 216.82122457895568\n",
      "Test: 90 Test_Reward: 273.721963703046\n",
      "Test: 93 Test_Reward: 282.78004707248283\n",
      "Test: 94 Test_Reward: 244.33619048800398\n",
      "Test: 95 Test_Reward: 296.71514427848524\n",
      "Test: 97 Test_Reward: 226.45716695503916\n",
      "Test: 98 Test_Reward: 299.96347920933465\n",
      "Test: 99 Test_Reward: 287.3778097734428\n",
      "Test finished with success 85 out of 100 iterations.\n",
      "Test average reward is 210.14622984090303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 600/3000 [37:54<16:46:21, 25.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 600 Episodic_Reward: 271.7148466290421\n",
      "Success in episode 600 with a reward of 271.7148466290421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 601/3000 [37:55<11:57:36, 17.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 601 with a reward of 250.833194134428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 602/3000 [37:56<8:35:31, 12.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 602 with a reward of 236.98525591092778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 603/3000 [38:15<9:52:45, 14.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 603 with a reward of 267.6157524491431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 604/3000 [38:17<7:09:44, 10.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 604 with a reward of 239.1099235680788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 605/3000 [38:18<5:14:26,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 605 with a reward of 263.70623620579994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 606/3000 [38:21<4:17:14,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 606 with a reward of 256.6433289204107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 607/3000 [38:45<7:43:53, 11.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 607 with a reward of 259.84989200298844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 608/3000 [38:46<5:42:38,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 608 with a reward of 229.63149255407592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 609/3000 [38:47<4:11:59,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 609 with a reward of 243.76551201329988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 610/3000 [38:49<3:20:48,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 610 Episodic_Reward: 234.71767652295935\n",
      "Success in episode 610 with a reward of 234.71767652295935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 611/3000 [39:15<7:30:48, 11.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 611 with a reward of 132.64911888896899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 612/3000 [39:16<5:29:04,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 612 with a reward of 270.60464758376725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 613/3000 [39:18<4:06:38,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 613 with a reward of 37.2460152972356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 614/3000 [39:20<3:14:41,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 614 with a reward of 240.63573295091845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 615/3000 [39:43<6:57:41, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 615 with a reward of 298.96115988421604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 616/3000 [39:45<5:10:51,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 616 with a reward of 269.02780148863064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 617/3000 [39:46<3:48:51,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 617 with a reward of 233.52774911234403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 618/3000 [39:47<2:54:31,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 618 with a reward of 252.1798812946433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 619/3000 [39:48<2:16:40,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 619 with a reward of 253.86083386612145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 620/3000 [40:07<5:19:11,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 620 Episodic_Reward: 234.27473367975227\n",
      "Success in episode 620 with a reward of 234.27473367975227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 621/3000 [40:08<3:57:22,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 621 with a reward of 252.43648893163925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 623/3000 [40:11<2:22:42,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 623 with a reward of 285.41282756430365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 624/3000 [40:26<4:43:53,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 624 with a reward of 25.908155425648786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 625/3000 [40:27<3:31:16,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 625 with a reward of 283.6578783313244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 626/3000 [40:30<2:56:24,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 626 with a reward of 237.39233383037097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 627/3000 [40:49<5:57:17,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 627 with a reward of 293.4455218443756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 628/3000 [40:51<4:23:22,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 628 with a reward of 264.6076772563671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 630/3000 [40:54<2:42:29,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 630 Episodic_Reward: 267.79441953191883\n",
      "Success in episode 630 with a reward of 267.79441953191883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 631/3000 [41:12<5:26:31,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 631 with a reward of 294.2163339200528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 632/3000 [41:13<4:00:27,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 632 with a reward of 243.99266797028187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 633/3000 [41:14<3:02:27,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 633 with a reward of 278.35774111915987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 634/3000 [41:15<2:22:38,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 634 with a reward of 274.50507871035836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 635/3000 [41:35<5:30:37,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 635 with a reward of 238.4680169626034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 636/3000 [41:36<4:04:50,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 636 with a reward of 278.30722531179305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 637/3000 [41:37<3:07:54,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 637 with a reward of 229.45399549185484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 638/3000 [41:39<2:25:12,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 638 with a reward of 273.8565628435206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 639/3000 [41:57<5:14:14,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 639 with a reward of 259.66588602381205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 640/3000 [41:58<3:52:54,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 640 Episodic_Reward: 283.8098125353335\n",
      "Success in episode 640 with a reward of 283.8098125353335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 641/3000 [41:59<2:56:44,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 641 with a reward of 281.8512009964736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 642/3000 [42:19<6:00:08,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 642 with a reward of 249.89299852898387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 643/3000 [42:20<4:23:56,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 643 with a reward of 9.483559921299644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 644/3000 [42:21<3:21:08,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 644 with a reward of 262.99727851896887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 645/3000 [42:23<2:35:41,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 645 with a reward of 263.15026683213574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 646/3000 [42:24<2:00:14,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 646 with a reward of 257.44193443400894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 647/3000 [42:46<5:45:31,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 647 with a reward of 287.82198560888924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 648/3000 [42:47<4:13:43,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 648 with a reward of 285.43817331609125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 649/3000 [42:48<3:12:40,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 649 with a reward of 288.79574182050294\n",
      "Running test\n",
      "Test: 1 Test_Reward: 243.92298021044942\n",
      "Test: 2 Test_Reward: 290.5893379427388\n",
      "Test: 3 Test_Reward: 272.7246250828602\n",
      "Test: 4 Test_Reward: 287.40318210253474\n",
      "Test: 5 Test_Reward: 290.57102303445237\n",
      "Test: 6 Test_Reward: 281.7918598648512\n",
      "Test: 7 Test_Reward: 278.0670475255522\n",
      "Test: 11 Test_Reward: 287.7144292210472\n",
      "Test: 13 Test_Reward: 281.15243270436764\n",
      "Test: 15 Test_Reward: 268.62835732316256\n",
      "Test: 16 Test_Reward: 259.32336459102567\n",
      "Test: 17 Test_Reward: 211.46487083574766\n",
      "Test: 18 Test_Reward: 259.0178141125734\n",
      "Test: 19 Test_Reward: 259.5328110201558\n",
      "Test: 20 Test_Reward: 237.2484570062725\n",
      "Test: 21 Test_Reward: 260.21127630564285\n",
      "Test: 22 Test_Reward: 210.3622924931594\n",
      "Test: 23 Test_Reward: 223.20954897794763\n",
      "Test: 24 Test_Reward: 233.35522106850024\n",
      "Test: 25 Test_Reward: 266.0757734345947\n",
      "Test: 26 Test_Reward: 267.81896867845984\n",
      "Test: 27 Test_Reward: 272.5608888752715\n",
      "Test: 28 Test_Reward: 276.68247867599837\n",
      "Test: 29 Test_Reward: 255.96350441404914\n",
      "Test: 30 Test_Reward: 260.83118883150456\n",
      "Test: 31 Test_Reward: 298.5516859733582\n",
      "Test: 32 Test_Reward: 274.0261141953765\n",
      "Test: 33 Test_Reward: 264.08417879046124\n",
      "Test: 34 Test_Reward: 231.77809790359078\n",
      "Test: 35 Test_Reward: 265.8630791272425\n",
      "Test: 36 Test_Reward: 258.2800430953229\n",
      "Test: 37 Test_Reward: 210.6799101849805\n",
      "Test: 38 Test_Reward: 254.6445068804938\n",
      "Test: 39 Test_Reward: 266.40769330619264\n",
      "Test: 40 Test_Reward: 249.45971736442982\n",
      "Test: 41 Test_Reward: 275.006614235864\n",
      "Test: 42 Test_Reward: 268.6527650704845\n",
      "Test: 43 Test_Reward: 268.88919702532337\n",
      "Test: 44 Test_Reward: 277.8913144166514\n",
      "Test: 45 Test_Reward: 261.60692607257965\n",
      "Test: 46 Test_Reward: 274.0478934455338\n",
      "Test: 47 Test_Reward: 257.64603670602753\n",
      "Test: 48 Test_Reward: 241.10782405683972\n",
      "Test: 49 Test_Reward: 255.5346374572678\n",
      "Test: 50 Test_Reward: 249.64966252018073\n",
      "Test: 51 Test_Reward: 283.1129613902408\n",
      "Test: 52 Test_Reward: 257.28518737668884\n",
      "Test: 53 Test_Reward: 219.40135541217006\n",
      "Test: 54 Test_Reward: 276.8821573852174\n",
      "Test: 55 Test_Reward: 215.08454399068654\n",
      "Test: 56 Test_Reward: 292.7245080377123\n",
      "Test: 57 Test_Reward: 300.64058383175995\n",
      "Test: 58 Test_Reward: 259.7328199464548\n",
      "Test: 59 Test_Reward: 274.54429313037554\n",
      "Test: 60 Test_Reward: 276.10888965889677\n",
      "Test: 61 Test_Reward: 253.31726206786024\n",
      "Test: 62 Test_Reward: 256.5743845277791\n",
      "Test: 63 Test_Reward: 265.66251119313654\n",
      "Test: 64 Test_Reward: 300.5877928969147\n",
      "Test: 65 Test_Reward: 274.9651726564732\n",
      "Test: 66 Test_Reward: 265.1871519771737\n",
      "Test: 67 Test_Reward: 232.90464944586267\n",
      "Test: 68 Test_Reward: 257.3203675038228\n",
      "Test: 69 Test_Reward: 278.96371930657267\n",
      "Test: 70 Test_Reward: 237.86761809337332\n",
      "Test: 71 Test_Reward: 266.917887456698\n",
      "Test: 72 Test_Reward: 225.15059350669418\n",
      "Test: 74 Test_Reward: 246.35332553358032\n",
      "Test: 75 Test_Reward: 242.62578211488577\n",
      "Test: 76 Test_Reward: 267.27648624022027\n",
      "Test: 77 Test_Reward: 255.64900643552127\n",
      "Test: 78 Test_Reward: 275.51645330728434\n",
      "Test: 79 Test_Reward: 211.13374348064298\n",
      "Test: 80 Test_Reward: 245.00449534967674\n",
      "Test: 81 Test_Reward: 289.3182397637662\n",
      "Test: 83 Test_Reward: 261.61687445624455\n",
      "Test: 84 Test_Reward: 254.30244983469288\n",
      "Test: 85 Test_Reward: 256.4601755683934\n",
      "Test: 86 Test_Reward: 277.6132205294185\n",
      "Test: 87 Test_Reward: 278.48446279125847\n",
      "Test: 88 Test_Reward: 254.34234386665284\n",
      "Test: 89 Test_Reward: 244.12447236746158\n",
      "Test: 90 Test_Reward: 288.96738018608323\n",
      "Test: 91 Test_Reward: 285.77359335298047\n",
      "Test: 92 Test_Reward: 295.94067944701953\n",
      "Test: 93 Test_Reward: 259.81856055695164\n",
      "Test: 94 Test_Reward: 305.94619180358916\n",
      "Test: 95 Test_Reward: 285.87914599818515\n",
      "Test: 96 Test_Reward: 265.0365456692076\n",
      "Test: 97 Test_Reward: 283.9060610967735\n",
      "Test: 98 Test_Reward: 252.098204023271\n",
      "Test: 99 Test_Reward: 278.74559354492817\n",
      "Test finished with success 92 out of 100 iterations.\n",
      "Test average reward is 242.65673223068603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 650/3000 [43:41<12:41:10, 19.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 650 Episodic_Reward: 256.6966286502968\n",
      "Success in episode 650 with a reward of 256.6966286502968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 651/3000 [43:59<12:14:44, 18.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 651 with a reward of 265.2681088208665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 652/3000 [43:59<8:44:52, 13.41s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 652 with a reward of 47.419615684009216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 653/3000 [44:01<6:23:26,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 653 with a reward of 280.9599275857702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 654/3000 [44:02<4:40:04,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 654 with a reward of 275.64977712961695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 655/3000 [44:20<6:44:20, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 655 with a reward of 282.7303393815591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 656/3000 [44:21<4:54:24,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 656 with a reward of 54.68627096921429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 657/3000 [44:22<3:37:03,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 657 with a reward of 257.0817021092234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 658/3000 [44:23<2:45:51,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 658 with a reward of 288.0234029898686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 659/3000 [44:24<2:12:32,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 659 with a reward of 246.1482377774787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 660/3000 [44:46<5:44:16,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 660 Episodic_Reward: 238.5171946710816\n",
      "Success in episode 660 with a reward of 238.5171946710816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 661/3000 [44:47<4:14:37,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 661 with a reward of 270.00874288976866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 662/3000 [44:48<3:13:59,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 662 with a reward of 277.19749055084424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 663/3000 [44:49<2:25:48,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 663 with a reward of 67.1611277057356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 664/3000 [45:09<5:32:17,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 664 with a reward of 276.0338010817211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 665/3000 [45:10<4:03:45,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 665 with a reward of 265.149251115944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 666/3000 [45:13<3:28:34,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 666 with a reward of 204.19751495762097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 667/3000 [45:14<2:37:06,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 667 with a reward of 243.70219121348504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 668/3000 [45:38<6:27:36,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 668 with a reward of 212.88029648315273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 669/3000 [45:40<4:54:50,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 669 with a reward of 209.65275101968004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 670/3000 [45:41<3:42:30,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 670 Episodic_Reward: 246.02771677232099\n",
      "Success in episode 670 with a reward of 246.02771677232099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 671/3000 [45:42<2:50:11,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 671 with a reward of 287.64181356051233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 672/3000 [46:05<6:25:07,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 672 with a reward of 276.2683854824778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 673/3000 [46:06<4:43:04,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 673 with a reward of 256.1538009739518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 674/3000 [46:08<3:30:59,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 674 with a reward of 264.6494427854809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▎       | 675/3000 [46:09<2:42:44,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 675 with a reward of 268.69209512373243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 676/3000 [46:27<5:20:59,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 676 with a reward of 271.56491484840734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 677/3000 [46:28<3:54:59,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 677 with a reward of 284.48047153188793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 678/3000 [46:28<2:53:35,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 678 with a reward of 225.88656439768994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 679/3000 [46:29<2:12:41,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 679 with a reward of 246.7591028574239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 680/3000 [46:30<1:45:44,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 680 Episodic_Reward: 293.9068217727265\n",
      "Success in episode 680 with a reward of 293.9068217727265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 681/3000 [46:50<4:57:34,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 681 with a reward of 237.28432682086964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 682/3000 [46:51<3:37:22,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 682 with a reward of 254.45273106418992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 683/3000 [46:52<2:49:42,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 683 with a reward of 281.2870303294085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 684/3000 [46:53<2:08:42,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 684 with a reward of 230.35410836022555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 686/3000 [47:14<3:56:57,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 686 with a reward of 265.8278222563995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 688/3000 [47:15<2:12:08,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 688 with a reward of 244.64295015753925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 689/3000 [47:16<1:44:07,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 689 with a reward of 267.03769099814104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 690/3000 [47:37<5:14:47,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 690 Episodic_Reward: 235.1987109693369\n",
      "Success in episode 690 with a reward of 235.1987109693369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 691/3000 [47:39<3:54:22,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 691 with a reward of 291.5732575366071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 692/3000 [47:40<2:55:22,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 692 with a reward of 243.81441597970712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 693/3000 [47:41<2:16:48,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 693 with a reward of 259.08553306885335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 694/3000 [48:03<5:50:24,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 694 with a reward of 216.65502384682873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 695/3000 [48:04<4:21:03,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 695 with a reward of 238.09739536136806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 696/3000 [48:05<3:16:01,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 696 with a reward of 239.44053569585577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 697/3000 [48:07<2:29:31,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 697 with a reward of 260.0062221667597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 699/3000 [48:28<4:11:08,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 699 with a reward of 289.0992104112163\n",
      "Running test\n",
      "Test: 1 Test_Reward: 265.2364604471478\n",
      "Test: 2 Test_Reward: 240.85341347062462\n",
      "Test: 3 Test_Reward: 281.13957843956814\n",
      "Test: 4 Test_Reward: 254.1595912607846\n",
      "Test: 5 Test_Reward: 265.74701035804446\n",
      "Test: 6 Test_Reward: 254.07059103865055\n",
      "Test: 7 Test_Reward: 280.935956301686\n",
      "Test: 8 Test_Reward: 259.667111027172\n",
      "Test: 9 Test_Reward: 287.25495062128755\n",
      "Test: 12 Test_Reward: 289.7923645589849\n",
      "Test: 13 Test_Reward: 212.33782543481112\n",
      "Test: 14 Test_Reward: 263.5277989122258\n",
      "Test: 15 Test_Reward: 259.3977343162785\n",
      "Test: 16 Test_Reward: 271.69268939667626\n",
      "Test: 17 Test_Reward: 234.37648954588084\n",
      "Test: 18 Test_Reward: 267.63144726702353\n",
      "Test: 20 Test_Reward: 255.33862262458337\n",
      "Test: 21 Test_Reward: 254.47858557870043\n",
      "Test: 22 Test_Reward: 243.82016385263185\n",
      "Test: 23 Test_Reward: 243.04412596944218\n",
      "Test: 24 Test_Reward: 288.09782626297203\n",
      "Test: 25 Test_Reward: 291.50874865219765\n",
      "Test: 26 Test_Reward: 220.40131389516188\n",
      "Test: 27 Test_Reward: 266.2513102107828\n",
      "Test: 29 Test_Reward: 275.93617889133736\n",
      "Test: 30 Test_Reward: 244.39057810780227\n",
      "Test: 31 Test_Reward: 255.71701285463948\n",
      "Test: 32 Test_Reward: 290.8708999175698\n",
      "Test: 33 Test_Reward: 256.1014446157726\n",
      "Test: 35 Test_Reward: 269.2467938203771\n",
      "Test: 36 Test_Reward: 247.60389115956605\n",
      "Test: 38 Test_Reward: 295.86708001003353\n",
      "Test: 39 Test_Reward: 281.79239381217565\n",
      "Test: 40 Test_Reward: 270.717843532671\n",
      "Test: 41 Test_Reward: 285.5639060464929\n",
      "Test: 42 Test_Reward: 279.0031131316148\n",
      "Test: 43 Test_Reward: 280.1391672449791\n",
      "Test: 44 Test_Reward: 290.5209777252528\n",
      "Test: 45 Test_Reward: 255.7704503342479\n",
      "Test: 46 Test_Reward: 226.20018384904887\n",
      "Test: 47 Test_Reward: 288.0674859443417\n",
      "Test: 48 Test_Reward: 237.1468840364341\n",
      "Test: 49 Test_Reward: 258.76246334582606\n",
      "Test: 50 Test_Reward: 203.39414223940094\n",
      "Test: 51 Test_Reward: 213.9132058756657\n",
      "Test: 52 Test_Reward: 245.28484918226573\n",
      "Test: 53 Test_Reward: 304.1259396968524\n",
      "Test: 54 Test_Reward: 297.298845971568\n",
      "Test: 55 Test_Reward: 280.84568723156247\n",
      "Test: 56 Test_Reward: 237.62081695252226\n",
      "Test: 57 Test_Reward: 239.18748508405054\n",
      "Test: 59 Test_Reward: 239.6190621419022\n",
      "Test: 61 Test_Reward: 268.4402831114744\n",
      "Test: 62 Test_Reward: 243.5803165668742\n",
      "Test: 63 Test_Reward: 222.33220153102553\n",
      "Test: 64 Test_Reward: 257.7986895581781\n",
      "Test: 65 Test_Reward: 228.43174518775396\n",
      "Test: 66 Test_Reward: 234.490110177695\n",
      "Test: 67 Test_Reward: 247.8316380602196\n",
      "Test: 68 Test_Reward: 275.5662239676643\n",
      "Test: 69 Test_Reward: 208.85521466491772\n",
      "Test: 71 Test_Reward: 258.2597531402498\n",
      "Test: 73 Test_Reward: 265.7938737390451\n",
      "Test: 75 Test_Reward: 216.10362559808425\n",
      "Test: 76 Test_Reward: 292.9685140960397\n",
      "Test: 77 Test_Reward: 300.71437097262276\n",
      "Test: 78 Test_Reward: 215.30219718462473\n",
      "Test: 79 Test_Reward: 276.10517172033894\n",
      "Test: 81 Test_Reward: 277.1528182594625\n",
      "Test: 82 Test_Reward: 257.5706275569444\n",
      "Test: 83 Test_Reward: 266.390145860474\n",
      "Test: 84 Test_Reward: 277.7252949632493\n",
      "Test: 85 Test_Reward: 293.69849945266606\n",
      "Test: 86 Test_Reward: 274.19667285892933\n",
      "Test: 87 Test_Reward: 272.86072660224113\n",
      "Test: 88 Test_Reward: 271.2460890991434\n",
      "Test: 89 Test_Reward: 267.81681712114084\n",
      "Test: 90 Test_Reward: 275.8845318197712\n",
      "Test: 91 Test_Reward: 290.9788355780846\n",
      "Test: 92 Test_Reward: 280.427997900375\n",
      "Test: 93 Test_Reward: 246.3929607388749\n",
      "Test: 94 Test_Reward: 234.50450776323217\n",
      "Test: 95 Test_Reward: 260.42366891739437\n",
      "Test: 97 Test_Reward: 295.66160458649097\n",
      "Test: 98 Test_Reward: 271.4196736800334\n",
      "Test: 99 Test_Reward: 277.6864166148108\n",
      "Test finished with success 86 out of 100 iterations.\n",
      "Test average reward is 233.3240729060964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 700/3000 [49:31<14:55:08, 23.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 700 Episodic_Reward: 244.03229218187258\n",
      "Success in episode 700 with a reward of 244.03229218187258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 701/3000 [49:32<10:38:06, 16.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 701 with a reward of 267.4172184897974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 702/3000 [49:51<11:06:51, 17.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 702 with a reward of 290.47412876678095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 703/3000 [49:52<8:00:41, 12.56s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 703 with a reward of 279.5456465964917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 704/3000 [49:53<5:47:50,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 704 with a reward of 271.1147928468465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 705/3000 [49:54<4:16:37,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 705 with a reward of 30.69618783610605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 706/3000 [50:12<6:26:48, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 706 with a reward of 279.786900317364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 707/3000 [50:13<4:43:00,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 707 with a reward of 49.37903099227839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 708/3000 [50:14<3:27:30,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 708 with a reward of 283.7476227603328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 709/3000 [50:16<2:39:20,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 709 with a reward of 252.60016830415822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 710/3000 [50:17<2:04:06,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 710 Episodic_Reward: 264.979373859501\n",
      "Success in episode 710 with a reward of 264.979373859501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 711/3000 [50:36<5:14:17,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 711 with a reward of 258.7331938886053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 713/3000 [50:53<5:27:14,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 713 with a reward of 143.3814368368409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 714/3000 [50:54<4:01:32,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 714 with a reward of 273.2876104809467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 715/3000 [50:55<3:01:37,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 715 with a reward of 243.54749754558856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 716/3000 [50:56<2:18:10,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 716 with a reward of 271.28463516261684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 717/3000 [50:57<1:48:53,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 717 with a reward of 256.3111875016353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 718/3000 [51:21<5:54:46,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 718 with a reward of 298.93885867879567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 719/3000 [51:23<4:22:39,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 719 with a reward of 308.0849133750845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 720/3000 [51:24<3:14:41,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 720 Episodic_Reward: 255.4201778431616\n",
      "Success in episode 720 with a reward of 255.4201778431616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 721/3000 [51:25<2:29:01,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 721 with a reward of 281.14934566737674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 722/3000 [51:26<1:54:22,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 722 with a reward of 227.27738915401386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 724/3000 [51:50<4:16:51,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 724 with a reward of 283.6658650310777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 725/3000 [51:54<3:43:10,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 725 with a reward of 293.67903412867855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 726/3000 [52:11<5:45:19,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 726 with a reward of 281.47378098560426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 727/3000 [52:12<4:12:42,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 727 with a reward of 231.78869562806375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 728/3000 [52:13<3:14:08,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 728 with a reward of 227.35996947324728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 729/3000 [52:14<2:27:57,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 729 with a reward of 289.8097747273751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 730/3000 [52:32<5:08:19,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 730 Episodic_Reward: 264.39302254787043\n",
      "Success in episode 730 with a reward of 264.39302254787043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 731/3000 [52:34<3:49:53,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 731 with a reward of 284.3832297228921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 732/3000 [52:38<3:25:46,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 732 with a reward of 286.04229303189857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 733/3000 [52:53<5:16:41,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 733 with a reward of 273.0502931914758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 734/3000 [52:54<3:57:08,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 734 with a reward of 289.5458289261221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 735/3000 [52:55<2:58:51,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 735 with a reward of 277.32663238391075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 736/3000 [52:57<2:17:30,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 736 with a reward of 229.17373968098804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 737/3000 [52:58<1:48:28,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 737 with a reward of 249.03510112161223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 738/3000 [53:18<5:07:52,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 738 with a reward of 258.46815621013013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 739/3000 [53:19<3:45:36,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 739 with a reward of 68.17615270552102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 740/3000 [53:20<2:49:15,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 740 Episodic_Reward: 274.0810660134489\n",
      "Success in episode 740 with a reward of 274.0810660134489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 741/3000 [53:21<2:10:30,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 741 with a reward of 294.5743786297148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 742/3000 [53:22<1:41:57,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 742 with a reward of 273.16525005488023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 743/3000 [53:40<4:35:47,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 743 with a reward of 36.7874423519591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 744/3000 [53:41<3:27:55,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 744 with a reward of 281.4486901336955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 745/3000 [53:42<2:36:48,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 745 with a reward of 229.54218214395803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 746/3000 [53:44<2:07:49,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 746 with a reward of 302.5592536191109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 747/3000 [54:03<4:57:52,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 747 with a reward of 272.7975181783495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 748/3000 [54:04<3:40:50,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 748 with a reward of 293.3198491639214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 749/3000 [54:05<2:46:33,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 749 with a reward of 247.5126296430211\n",
      "Running test\n",
      "Test: 1 Test_Reward: 278.99156682967924\n",
      "Test: 3 Test_Reward: 279.3240089747013\n",
      "Test: 4 Test_Reward: 263.2908254791437\n",
      "Test: 5 Test_Reward: 271.39584028942073\n",
      "Test: 6 Test_Reward: 279.6235558284562\n",
      "Test: 7 Test_Reward: 263.8212753482501\n",
      "Test: 8 Test_Reward: 235.03973952541855\n",
      "Test: 9 Test_Reward: 263.75529331143844\n",
      "Test: 10 Test_Reward: 231.91784571679904\n",
      "Test: 11 Test_Reward: 266.72749425390293\n",
      "Test: 12 Test_Reward: 273.6957218635681\n",
      "Test: 13 Test_Reward: 263.1009675813282\n",
      "Test: 14 Test_Reward: 267.39961342616414\n",
      "Test: 15 Test_Reward: 260.62072306728146\n",
      "Test: 16 Test_Reward: 272.82611935884273\n",
      "Test: 17 Test_Reward: 272.92263608953397\n",
      "Test: 18 Test_Reward: 203.20673128768308\n",
      "Test: 19 Test_Reward: 272.35090988318643\n",
      "Test: 20 Test_Reward: 298.03759310321317\n",
      "Test: 21 Test_Reward: 232.26556463243702\n",
      "Test: 22 Test_Reward: 285.3424111152388\n",
      "Test: 23 Test_Reward: 254.3898201942634\n",
      "Test: 24 Test_Reward: 237.05384574134098\n",
      "Test: 25 Test_Reward: 251.9327221083737\n",
      "Test: 26 Test_Reward: 309.54985078729624\n",
      "Test: 27 Test_Reward: 258.23084475594214\n",
      "Test: 28 Test_Reward: 205.0023736318804\n",
      "Test: 29 Test_Reward: 276.1924302396526\n",
      "Test: 30 Test_Reward: 220.77013801488204\n",
      "Test: 31 Test_Reward: 293.66804126086873\n",
      "Test: 32 Test_Reward: 295.16419487576275\n",
      "Test: 33 Test_Reward: 260.3070603673316\n",
      "Test: 34 Test_Reward: 295.3919325325043\n",
      "Test: 35 Test_Reward: 230.44964402186906\n",
      "Test: 36 Test_Reward: 238.86130858242186\n",
      "Test: 37 Test_Reward: 258.5891595000285\n",
      "Test: 38 Test_Reward: 269.0839187688822\n",
      "Test: 39 Test_Reward: 254.6618397352372\n",
      "Test: 40 Test_Reward: 300.06076371409154\n",
      "Test: 41 Test_Reward: 279.2638169003591\n",
      "Test: 42 Test_Reward: 269.56328254300917\n",
      "Test: 43 Test_Reward: 230.97260769439126\n",
      "Test: 45 Test_Reward: 273.358575165878\n",
      "Test: 46 Test_Reward: 232.16050891635774\n",
      "Test: 47 Test_Reward: 278.96754466578864\n",
      "Test: 48 Test_Reward: 238.20351384661967\n",
      "Test: 49 Test_Reward: 294.6117467044679\n",
      "Test: 50 Test_Reward: 276.38061346143456\n",
      "Test: 51 Test_Reward: 231.48899112067826\n",
      "Test: 52 Test_Reward: 257.3614317097707\n",
      "Test: 53 Test_Reward: 256.90999070794544\n",
      "Test: 54 Test_Reward: 263.2796938857945\n",
      "Test: 55 Test_Reward: 263.790690863784\n",
      "Test: 56 Test_Reward: 286.09637972192684\n",
      "Test: 57 Test_Reward: 264.2914587687601\n",
      "Test: 58 Test_Reward: 250.4518900260009\n",
      "Test: 59 Test_Reward: 260.2232177292083\n",
      "Test: 60 Test_Reward: 260.4469728159798\n",
      "Test: 61 Test_Reward: 247.21252843474173\n",
      "Test: 62 Test_Reward: 284.3537617937709\n",
      "Test: 63 Test_Reward: 241.12927434306786\n",
      "Test: 65 Test_Reward: 235.01300960853376\n",
      "Test: 66 Test_Reward: 289.4480745003336\n",
      "Test: 67 Test_Reward: 289.2043518540913\n",
      "Test: 68 Test_Reward: 216.8323732356617\n",
      "Test: 69 Test_Reward: 272.15700276530674\n",
      "Test: 70 Test_Reward: 284.24743057102773\n",
      "Test: 71 Test_Reward: 249.00958390122372\n",
      "Test: 72 Test_Reward: 295.7036503704721\n",
      "Test: 73 Test_Reward: 281.9096358134585\n",
      "Test: 74 Test_Reward: 271.23460290356843\n",
      "Test: 75 Test_Reward: 259.221514821715\n",
      "Test: 76 Test_Reward: 289.38623605164867\n",
      "Test: 77 Test_Reward: 238.43429652406746\n",
      "Test: 78 Test_Reward: 248.31969038099732\n",
      "Test: 79 Test_Reward: 295.49618727399513\n",
      "Test: 80 Test_Reward: 307.74997254426546\n",
      "Test: 81 Test_Reward: 233.76731562402435\n",
      "Test: 82 Test_Reward: 220.70296115364013\n",
      "Test: 83 Test_Reward: 294.2062890020346\n",
      "Test: 84 Test_Reward: 235.1971936795613\n",
      "Test: 85 Test_Reward: 304.6851031940902\n",
      "Test: 86 Test_Reward: 261.1694662717396\n",
      "Test: 87 Test_Reward: 296.62180980557866\n",
      "Test: 88 Test_Reward: 269.03591858334613\n",
      "Test: 89 Test_Reward: 291.96605390790967\n",
      "Test: 90 Test_Reward: 308.44999292717824\n",
      "Test: 91 Test_Reward: 266.0820991029598\n",
      "Test: 92 Test_Reward: 306.03403290693336\n",
      "Test: 93 Test_Reward: 254.3231118269756\n",
      "Test: 95 Test_Reward: 242.65506198397225\n",
      "Test: 96 Test_Reward: 282.538273631807\n",
      "Test: 97 Test_Reward: 243.1516503318915\n",
      "Test: 98 Test_Reward: 248.0943801940316\n",
      "Test: 99 Test_Reward: 264.63662735679804\n",
      "Test finished with success 95 out of 100 iterations.\n",
      "Test average reward is 254.6763266249517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 750/3000 [54:48<9:58:20, 15.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 750 Episodic_Reward: 264.19379369997364\n",
      "Success in episode 750 with a reward of 264.19379369997364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 751/3000 [55:07<10:38:13, 17.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 751 with a reward of 292.02491156008307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 752/3000 [55:08<7:37:23, 12.21s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 752 with a reward of 260.86624190833334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 753/3000 [55:09<5:34:05,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 753 with a reward of 298.65367675228754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 754/3000 [55:11<4:07:10,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 754 with a reward of 262.7358546723425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 756/3000 [55:32<4:52:52,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 756 with a reward of 263.9943794917545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 757/3000 [55:33<3:35:56,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 757 with a reward of 283.9487361794582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 758/3000 [55:34<2:43:39,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 758 with a reward of 254.8789129181119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 759/3000 [55:35<2:05:37,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 759 with a reward of 276.5612061057941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 760/3000 [55:57<5:30:15,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 760 Episodic_Reward: 242.3476303193914\n",
      "Success in episode 760 with a reward of 242.3476303193914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 761/3000 [55:58<4:02:16,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 761 with a reward of 251.45011927869885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 762/3000 [56:00<3:14:12,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 762 with a reward of 271.61122917619025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 763/3000 [56:01<2:28:02,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 763 with a reward of 283.94761334019745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 764/3000 [56:23<5:48:42,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 764 with a reward of 295.49554857246204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 765/3000 [56:24<4:16:32,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 765 with a reward of 260.49063265218194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 766/3000 [56:25<3:12:02,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 766 with a reward of 263.0355658364578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 767/3000 [56:26<2:28:47,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 767 with a reward of 245.9373250014926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 768/3000 [56:45<5:11:36,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 768 with a reward of 275.91930898918247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 769/3000 [56:46<3:51:28,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 769 with a reward of 265.45969832363005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 770/3000 [56:48<2:56:27,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 770 Episodic_Reward: 252.2460963012819\n",
      "Success in episode 770 with a reward of 252.2460963012819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 771/3000 [56:49<2:16:01,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 771 with a reward of 278.3977140348551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 772/3000 [57:08<5:04:59,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 772 with a reward of 275.8692263534516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 773/3000 [57:09<3:45:19,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 773 with a reward of 288.35557829616937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 774/3000 [57:10<2:48:52,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 774 with a reward of 283.97531032327487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 775/3000 [57:11<2:10:05,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 775 with a reward of 263.42027712384225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 776/3000 [57:29<4:53:04,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 776 with a reward of 249.39948017142103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 777/3000 [57:30<3:39:49,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 777 with a reward of 274.72141840247633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 778/3000 [57:31<2:45:11,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 778 with a reward of 222.57969089690687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 779/3000 [57:32<2:07:05,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 779 with a reward of 299.10503482997456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 780/3000 [57:50<4:49:52,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 780 Episodic_Reward: 284.30682947567345\n",
      "Success in episode 780 with a reward of 284.30682947567345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 781/3000 [57:51<3:35:19,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 781 with a reward of 261.90677108486227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 782/3000 [57:54<3:03:39,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 782 with a reward of 290.21846489545396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 783/3000 [58:11<5:06:41,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 783 with a reward of 284.8595214502297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 784/3000 [58:12<3:48:21,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 784 with a reward of 272.45338274985454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 785/3000 [58:13<2:58:26,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 785 with a reward of 216.64249324595045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 786/3000 [58:14<2:16:01,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 786 with a reward of 245.35246203353458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 787/3000 [58:37<5:46:20,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 787 with a reward of 258.81798828099795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 788/3000 [58:38<4:14:03,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 788 with a reward of 246.3235423079377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 789/3000 [58:39<3:09:27,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 789 with a reward of 275.5218707964756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 790/3000 [58:41<2:29:25,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 790 Episodic_Reward: 262.9847170389437\n",
      "Success in episode 790 with a reward of 262.9847170389437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 791/3000 [59:00<5:19:30,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 791 with a reward of 292.7222303416834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 792/3000 [59:03<4:14:17,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 792 with a reward of 259.80901703462314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 793/3000 [59:05<3:23:02,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 793 with a reward of 263.30787970459596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 794/3000 [59:26<6:06:26,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 794 with a reward of 293.0166756437885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 795/3000 [59:27<4:28:54,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 795 with a reward of 258.7655895105303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 796/3000 [59:29<3:33:30,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 796 with a reward of 287.4707347108672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 797/3000 [59:31<2:44:59,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 797 with a reward of 299.9863135154968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 798/3000 [59:56<6:30:27, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 798 with a reward of 241.148841320683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 799/3000 [59:57<4:44:24,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 799 with a reward of 290.30564213718037\n",
      "Running test\n",
      "Test: 1 Test_Reward: 272.3154876878052\n",
      "Test: 2 Test_Reward: 249.40550303590138\n",
      "Test: 3 Test_Reward: 227.28062983220346\n",
      "Test: 4 Test_Reward: 247.6180976220382\n",
      "Test: 5 Test_Reward: 274.79449474573346\n",
      "Test: 6 Test_Reward: 249.44866350882944\n",
      "Test: 7 Test_Reward: 264.12477789021403\n",
      "Test: 8 Test_Reward: 285.3428117505544\n",
      "Test: 9 Test_Reward: 278.3368575206314\n",
      "Test: 10 Test_Reward: 268.5409624135469\n",
      "Test: 11 Test_Reward: 293.25695271482687\n",
      "Test: 12 Test_Reward: 253.98415765511942\n",
      "Test: 13 Test_Reward: 250.1891197438865\n",
      "Test: 14 Test_Reward: 268.0050813289109\n",
      "Test: 15 Test_Reward: 277.5939129745587\n",
      "Test: 16 Test_Reward: 263.86301304274605\n",
      "Test: 17 Test_Reward: 259.5981545609607\n",
      "Test: 18 Test_Reward: 257.3456816988593\n",
      "Test: 19 Test_Reward: 304.24497299679325\n",
      "Test: 20 Test_Reward: 229.2518564356319\n",
      "Test: 21 Test_Reward: 239.60946491228853\n",
      "Test: 22 Test_Reward: 271.12054257302344\n",
      "Test: 23 Test_Reward: 286.31874883722753\n",
      "Test: 24 Test_Reward: 279.8972605020091\n",
      "Test: 25 Test_Reward: 226.46562627080158\n",
      "Test: 26 Test_Reward: 297.89970163619483\n",
      "Test: 27 Test_Reward: 300.40484374042563\n",
      "Test: 28 Test_Reward: 259.6820573977652\n",
      "Test: 29 Test_Reward: 235.3361121883403\n",
      "Test: 30 Test_Reward: 245.11247776664058\n",
      "Test: 31 Test_Reward: 292.994290703939\n",
      "Test: 32 Test_Reward: 275.0832321662657\n",
      "Test: 33 Test_Reward: 268.46036960082205\n",
      "Test: 34 Test_Reward: 275.7018242870238\n",
      "Test: 35 Test_Reward: 273.4899207484923\n",
      "Test: 36 Test_Reward: 250.55611600386953\n",
      "Test: 37 Test_Reward: 250.36638269164948\n",
      "Test: 38 Test_Reward: 299.97975966351044\n",
      "Test: 39 Test_Reward: 300.3599166831477\n",
      "Test: 40 Test_Reward: 260.84559734369\n",
      "Test: 42 Test_Reward: 220.01587133688068\n",
      "Test: 43 Test_Reward: 263.91781891761207\n",
      "Test: 44 Test_Reward: 256.7525096785547\n",
      "Test: 45 Test_Reward: 241.62549610104023\n",
      "Test: 46 Test_Reward: 247.76211326239203\n",
      "Test: 47 Test_Reward: 275.88340628714207\n",
      "Test: 48 Test_Reward: 211.57074048354704\n",
      "Test: 49 Test_Reward: 280.57693211416307\n",
      "Test: 50 Test_Reward: 260.59509104862497\n",
      "Test: 51 Test_Reward: 266.6545057424921\n",
      "Test: 52 Test_Reward: 301.06717327498285\n",
      "Test: 53 Test_Reward: 226.00638088067862\n",
      "Test: 54 Test_Reward: 278.6923958562586\n",
      "Test: 55 Test_Reward: 294.3096241510797\n",
      "Test: 56 Test_Reward: 274.60184782725366\n",
      "Test: 57 Test_Reward: 238.81944572804258\n",
      "Test: 58 Test_Reward: 270.76865233956715\n",
      "Test: 59 Test_Reward: 255.32248614642248\n",
      "Test: 60 Test_Reward: 286.24179147736515\n",
      "Test: 61 Test_Reward: 264.7461715206119\n",
      "Test: 63 Test_Reward: 247.031345837615\n",
      "Test: 64 Test_Reward: 211.65629184957993\n",
      "Test: 65 Test_Reward: 292.8683080513177\n",
      "Test: 67 Test_Reward: 278.5144716534011\n",
      "Test: 68 Test_Reward: 257.53092818011487\n",
      "Test: 69 Test_Reward: 297.49412384103334\n",
      "Test: 70 Test_Reward: 301.94023688702214\n",
      "Test: 71 Test_Reward: 289.9782757336146\n",
      "Test: 72 Test_Reward: 201.01639842540808\n",
      "Test: 73 Test_Reward: 275.3338135471324\n",
      "Test: 74 Test_Reward: 302.0340029368089\n",
      "Test: 75 Test_Reward: 304.5975133995065\n",
      "Test: 76 Test_Reward: 306.2013417213543\n",
      "Test: 77 Test_Reward: 277.8628092749343\n",
      "Test: 78 Test_Reward: 300.04210515615364\n",
      "Test: 79 Test_Reward: 211.6548124140831\n",
      "Test: 80 Test_Reward: 303.4141907774276\n",
      "Test: 81 Test_Reward: 305.42620710599135\n",
      "Test: 82 Test_Reward: 210.36688192579464\n",
      "Test: 83 Test_Reward: 250.03188210699403\n",
      "Test: 84 Test_Reward: 287.95311736381166\n",
      "Test: 85 Test_Reward: 246.07026079726066\n",
      "Test: 86 Test_Reward: 255.65118461230304\n",
      "Test: 87 Test_Reward: 294.9964108176143\n",
      "Test: 88 Test_Reward: 218.7671450360844\n",
      "Test: 89 Test_Reward: 267.4026935415029\n",
      "Test: 90 Test_Reward: 269.0184256422068\n",
      "Test: 91 Test_Reward: 238.29475842751054\n",
      "Test: 92 Test_Reward: 217.22494748005295\n",
      "Test: 93 Test_Reward: 290.9493274927108\n",
      "Test: 94 Test_Reward: 258.25306019746574\n",
      "Test: 95 Test_Reward: 276.3747680385587\n",
      "Test: 96 Test_Reward: 274.35267472639805\n",
      "Test: 97 Test_Reward: 254.43816589705426\n",
      "Test: 98 Test_Reward: 288.6718543501315\n",
      "Test: 99 Test_Reward: 241.63175458668493\n",
      "Test finished with success 96 out of 100 iterations.\n",
      "Test average reward is 251.87750962330577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 800/3000 [1:00:42<11:37:42, 19.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 800 Episodic_Reward: 253.39203255449135\n",
      "Success in episode 800 with a reward of 253.39203255449135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 801/3000 [1:00:43<8:18:56, 13.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 801 with a reward of 227.83836817238398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 802/3000 [1:00:44<5:59:54,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 802 with a reward of 247.46727872352426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 803/3000 [1:01:04<7:52:58, 12.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 803 with a reward of 259.41544716160445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 804/3000 [1:01:05<5:41:31,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 804 with a reward of 274.3063969788376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 805/3000 [1:01:06<4:11:50,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 805 with a reward of 279.54047156866613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 806/3000 [1:01:07<3:06:58,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 806 with a reward of 264.45311117694644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 807/3000 [1:01:08<2:25:22,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 807 with a reward of 279.08348501510113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 808/3000 [1:01:35<6:31:51, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 808 with a reward of 227.72207342681597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 809/3000 [1:01:36<4:45:06,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 809 with a reward of 266.4096938718221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 810/3000 [1:01:37<3:31:44,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 810 Episodic_Reward: 264.06789842790454\n",
      "Success in episode 810 with a reward of 264.06789842790454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 811/3000 [1:01:38<2:40:34,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 811 with a reward of 304.484790329921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 812/3000 [1:01:58<5:25:01,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 812 with a reward of 217.34953470423943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 813/3000 [1:01:59<4:00:26,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 813 with a reward of 290.1904340133876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 814/3000 [1:02:00<3:01:09,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 814 with a reward of 277.7609417128152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 815/3000 [1:02:01<2:18:42,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 815 with a reward of 234.54266517231878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 816/3000 [1:02:19<4:50:01,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 816 with a reward of 261.5669920813999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 817/3000 [1:02:20<3:33:52,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 817 with a reward of 271.70230709246886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 818/3000 [1:02:22<2:56:27,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 818 with a reward of 253.67587696648079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 819/3000 [1:02:23<2:14:41,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 819 with a reward of 255.31681347096333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 820/3000 [1:02:41<4:51:39,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 820 Episodic_Reward: 283.8701258990028\n",
      "Success in episode 820 with a reward of 283.8701258990028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 821/3000 [1:02:42<3:35:30,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 821 with a reward of 272.87129482648527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 822/3000 [1:02:44<2:44:18,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 822 with a reward of 295.4883501365157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 823/3000 [1:02:45<2:05:28,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 823 with a reward of 264.2450718043252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 824/3000 [1:02:46<1:39:50,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 824 with a reward of 242.13737629601738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 825/3000 [1:03:07<5:02:36,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 825 with a reward of 270.75125680697863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 826/3000 [1:03:08<3:45:34,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 826 with a reward of 274.6760444062171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 827/3000 [1:03:10<2:51:36,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 827 with a reward of 277.33478725077487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 828/3000 [1:03:11<2:10:58,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 828 with a reward of 236.663294740191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 829/3000 [1:03:12<1:44:20,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 829 with a reward of 301.79209402853166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 830/3000 [1:03:33<5:03:47,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 830 Episodic_Reward: 251.4656667638942\n",
      "Success in episode 830 with a reward of 251.4656667638942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 831/3000 [1:03:34<3:44:37,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 831 with a reward of 269.02081222906605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 832/3000 [1:03:36<2:56:54,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking good in 832 with a reward of 175.03873575227053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 833/3000 [1:03:37<2:17:17,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 833 with a reward of 292.1969682538354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 834/3000 [1:03:56<4:54:07,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 834 with a reward of 284.4773508646136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 835/3000 [1:03:57<3:36:29,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 835 with a reward of 242.2335957155164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 836/3000 [1:03:58<2:43:59,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 836 with a reward of 295.41002114665923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 837/3000 [1:03:59<2:04:25,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 837 with a reward of 272.4301103103923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 838/3000 [1:04:00<1:38:18,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 838 with a reward of 286.41565753727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 839/3000 [1:04:21<4:58:50,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 839 with a reward of 259.7773369860863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 840/3000 [1:04:22<3:40:44,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 840 Episodic_Reward: 279.7947090814636\n",
      "Success in episode 840 with a reward of 279.7947090814636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 841/3000 [1:04:23<2:45:44,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 841 with a reward of 270.8641638855746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 842/3000 [1:04:24<2:05:56,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 842 with a reward of 19.171282289375156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 843/3000 [1:04:25<1:42:42,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 843 with a reward of 299.40832331574893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 844/3000 [1:04:45<4:45:37,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 844 with a reward of 244.93501423129652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 845/3000 [1:04:46<3:30:24,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 845 with a reward of 225.78597570752055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 846/3000 [1:04:47<2:37:08,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 846 with a reward of 256.41996233171926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 847/3000 [1:04:48<2:02:30,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 847 with a reward of 283.6371715208824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 848/3000 [1:04:50<1:42:01,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 848 with a reward of 219.6829264304321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 849/3000 [1:05:11<4:59:42,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 849 with a reward of 296.51137152554287\n",
      "Running test\n",
      "Test: 1 Test_Reward: 256.39920988149237\n",
      "Test: 2 Test_Reward: 288.1853984740023\n",
      "Test: 3 Test_Reward: 294.0282431714601\n",
      "Test: 4 Test_Reward: 284.45373109511104\n",
      "Test: 5 Test_Reward: 292.3750186199287\n",
      "Test: 6 Test_Reward: 273.44592887902604\n",
      "Test: 7 Test_Reward: 284.6798713169168\n",
      "Test: 8 Test_Reward: 305.7333941919125\n",
      "Test: 9 Test_Reward: 235.70636944770035\n",
      "Test: 10 Test_Reward: 227.93713096483557\n",
      "Test: 11 Test_Reward: 284.0760129995546\n",
      "Test: 12 Test_Reward: 265.9728969809547\n",
      "Test: 14 Test_Reward: 257.4921907766627\n",
      "Test: 15 Test_Reward: 215.13199845443881\n",
      "Test: 17 Test_Reward: 276.94764442403306\n",
      "Test: 18 Test_Reward: 295.26616470444844\n",
      "Test: 19 Test_Reward: 246.99185518633547\n",
      "Test: 20 Test_Reward: 293.5592511120219\n",
      "Test: 21 Test_Reward: 267.9573173052393\n",
      "Test: 22 Test_Reward: 258.1254257781412\n",
      "Test: 24 Test_Reward: 261.3463622492693\n",
      "Test: 25 Test_Reward: 260.0207928180115\n",
      "Test: 26 Test_Reward: 243.97934846922226\n",
      "Test: 27 Test_Reward: 256.95350395820856\n",
      "Test: 28 Test_Reward: 297.3389358611192\n",
      "Test: 30 Test_Reward: 260.14364392740003\n",
      "Test: 31 Test_Reward: 241.36219682901472\n",
      "Test: 32 Test_Reward: 292.02489054762276\n",
      "Test: 33 Test_Reward: 254.90977979346513\n",
      "Test: 34 Test_Reward: 304.2635641522028\n",
      "Test: 35 Test_Reward: 254.16103066773397\n",
      "Test: 36 Test_Reward: 255.13667521474173\n",
      "Test: 37 Test_Reward: 279.12483052578295\n",
      "Test: 38 Test_Reward: 274.96944978110025\n",
      "Test: 39 Test_Reward: 236.451944222163\n",
      "Test: 40 Test_Reward: 290.56302494848944\n",
      "Test: 41 Test_Reward: 270.94262880657527\n",
      "Test: 42 Test_Reward: 225.29364166931515\n",
      "Test: 43 Test_Reward: 234.73350157726827\n",
      "Test: 44 Test_Reward: 302.11189571773207\n",
      "Test: 45 Test_Reward: 220.57559035276398\n",
      "Test: 46 Test_Reward: 256.52193643671416\n",
      "Test: 47 Test_Reward: 281.56510572110204\n",
      "Test: 48 Test_Reward: 283.4155498308181\n",
      "Test: 49 Test_Reward: 302.5433324420969\n",
      "Test: 50 Test_Reward: 226.45559116902774\n",
      "Test: 51 Test_Reward: 274.70816471913236\n",
      "Test: 52 Test_Reward: 251.18044831316138\n",
      "Test: 53 Test_Reward: 232.39870176861245\n",
      "Test: 54 Test_Reward: 269.31335651784843\n",
      "Test: 55 Test_Reward: 247.16208206354912\n",
      "Test: 56 Test_Reward: 271.5224376465968\n",
      "Test: 57 Test_Reward: 283.8630791569501\n",
      "Test: 58 Test_Reward: 305.6369680083247\n",
      "Test: 59 Test_Reward: 283.85676328677255\n",
      "Test: 60 Test_Reward: 278.3990072328295\n",
      "Test: 61 Test_Reward: 311.7504911453526\n",
      "Test: 62 Test_Reward: 244.00049876856133\n",
      "Test: 63 Test_Reward: 309.69382529833507\n",
      "Test: 64 Test_Reward: 310.93357707745895\n",
      "Test: 65 Test_Reward: 248.20703307786593\n",
      "Test: 66 Test_Reward: 277.87300060455436\n",
      "Test: 67 Test_Reward: 255.07658630142504\n",
      "Test: 68 Test_Reward: 264.16313900998506\n",
      "Test: 69 Test_Reward: 259.6074812594792\n",
      "Test: 70 Test_Reward: 234.2247149180622\n",
      "Test: 71 Test_Reward: 227.95519666585477\n",
      "Test: 72 Test_Reward: 248.41944027453445\n",
      "Test: 73 Test_Reward: 236.97761485861056\n",
      "Test: 74 Test_Reward: 260.4815924701694\n",
      "Test: 75 Test_Reward: 308.60383257846024\n",
      "Test: 76 Test_Reward: 284.8655298849522\n",
      "Test: 77 Test_Reward: 271.0814016957803\n",
      "Test: 78 Test_Reward: 287.56081515724077\n",
      "Test: 79 Test_Reward: 235.8103133193653\n",
      "Test: 80 Test_Reward: 273.6597912536714\n",
      "Test: 81 Test_Reward: 307.4029632554541\n",
      "Test: 82 Test_Reward: 296.63266832761207\n",
      "Test: 83 Test_Reward: 277.17854490959445\n",
      "Test: 84 Test_Reward: 283.72961581149264\n",
      "Test: 86 Test_Reward: 266.35256773372646\n",
      "Test: 87 Test_Reward: 226.90282419517249\n",
      "Test: 88 Test_Reward: 284.60819939896294\n",
      "Test: 90 Test_Reward: 273.4026337150333\n",
      "Test: 91 Test_Reward: 246.34008769031192\n",
      "Test: 92 Test_Reward: 299.82247916483755\n",
      "Test: 93 Test_Reward: 253.88140049049727\n",
      "Test: 94 Test_Reward: 278.6031190426036\n",
      "Test: 95 Test_Reward: 266.7761860417096\n",
      "Test: 96 Test_Reward: 256.77790275091644\n",
      "Test: 97 Test_Reward: 233.29255770161686\n",
      "Test: 98 Test_Reward: 281.180114504922\n",
      "Test: 99 Test_Reward: 210.06552876171463\n",
      "Test finished with success 93 out of 100 iterations.\n",
      "Test average reward is 253.67119181614697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 850/3000 [1:05:54<11:12:22, 18.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 850 Episodic_Reward: -48.899501160208324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 851/3000 [1:05:55<8:02:41, 13.48s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 851 with a reward of 290.7231246332794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 852/3000 [1:05:56<5:50:26,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 852 with a reward of 294.3401008479414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 853/3000 [1:06:13<6:59:16, 11.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 853 with a reward of 296.84662872153535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 854/3000 [1:06:14<5:04:47,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 854 with a reward of 279.6240102460574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 855/3000 [1:06:15<3:45:08,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 855 with a reward of 292.415857182953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 856/3000 [1:06:16<2:50:25,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 856 with a reward of 295.0128502514423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 857/3000 [1:06:17<2:09:34,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 857 with a reward of 238.85950573688086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 858/3000 [1:06:44<6:19:12, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 858 with a reward of 282.14054406269054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 859/3000 [1:06:45<4:36:52,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 859 with a reward of 256.5018183785013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 860/3000 [1:06:46<3:26:53,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 860 Episodic_Reward: 248.00604127563966\n",
      "Success in episode 860 with a reward of 248.00604127563966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 861/3000 [1:06:47<2:35:34,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 861 with a reward of 301.8275655789405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 862/3000 [1:07:08<5:26:52,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 862 with a reward of 246.27531454060792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 863/3000 [1:07:09<3:59:33,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 863 with a reward of 275.946547430968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 864/3000 [1:07:10<3:07:39,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 864 with a reward of 227.46727811004152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 865/3000 [1:07:11<2:22:06,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 865 with a reward of 276.57750686098757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 866/3000 [1:07:31<5:05:48,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 866 with a reward of 285.3287057970239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 867/3000 [1:07:32<3:44:03,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 867 with a reward of 274.6859055187435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 868/3000 [1:07:33<2:47:57,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 868 with a reward of 239.79100211317441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 869/3000 [1:07:34<2:08:42,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 869 with a reward of 253.44039866939582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 870/3000 [1:07:35<1:40:52,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 870 Episodic_Reward: 261.6639103464534\n",
      "Success in episode 870 with a reward of 261.6639103464534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 872/3000 [1:07:55<3:19:22,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 872 with a reward of 276.3311232264406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 873/3000 [1:07:56<2:30:33,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 873 with a reward of 236.47372881365504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 874/3000 [1:07:57<1:58:24,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 874 with a reward of 294.1576011822071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 875/3000 [1:08:15<4:40:55,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 875 with a reward of 253.8739155869244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 876/3000 [1:08:16<3:27:40,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 876 with a reward of 289.1619942524188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 877/3000 [1:08:17<2:36:02,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 877 with a reward of 256.127031853722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 878/3000 [1:08:19<2:01:48,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 878 with a reward of 302.77621382722805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 879/3000 [1:08:37<4:39:07,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 879 with a reward of 268.7050768862464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 880/3000 [1:08:40<3:48:42,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 880 Episodic_Reward: 284.0694923629172\n",
      "Success in episode 880 with a reward of 284.0694923629172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 881/3000 [1:08:41<2:51:09,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 881 with a reward of 264.1470585825733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 882/3000 [1:08:57<4:43:59,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 882 with a reward of 254.70496561496114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 883/3000 [1:08:58<3:32:32,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 883 with a reward of 244.07142279194775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 884/3000 [1:08:59<2:40:29,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 884 with a reward of 18.64301074275032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 885/3000 [1:09:19<5:23:40,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 885 with a reward of 254.895862543264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 886/3000 [1:09:20<3:58:30,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 886 with a reward of 309.50864250138045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 887/3000 [1:09:21<2:57:55,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting somewhere in 887 with a reward of 66.00225471797935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 888/3000 [1:09:22<2:16:50,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 888 with a reward of 280.1628203565919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 889/3000 [1:09:40<4:37:18,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 889 with a reward of 311.580671103887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 890/3000 [1:09:41<3:24:22,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 890 Episodic_Reward: 301.37435558767845\n",
      "Success in episode 890 with a reward of 301.37435558767845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 891/3000 [1:09:44<2:56:19,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 891 with a reward of 284.8877376791803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 892/3000 [1:09:59<4:42:20,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 892 with a reward of 252.99296482850625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 893/3000 [1:10:00<3:30:31,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 893 with a reward of 283.5911192198984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 894/3000 [1:10:02<2:42:30,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 894 with a reward of 295.152943146956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 895/3000 [1:10:03<2:04:50,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 895 with a reward of 282.0054639198336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 896/3000 [1:10:22<4:53:09,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 896 with a reward of 305.9037421843301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 897/3000 [1:10:23<3:35:28,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 897 with a reward of 301.3681947865818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 898/3000 [1:10:25<2:45:04,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 898 with a reward of 284.6320586386828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 899/3000 [1:10:26<2:08:00,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 899 with a reward of 232.18701545079134\n",
      "Running test\n",
      "Test: 1 Test_Reward: 300.4174515534189\n",
      "Test: 2 Test_Reward: 269.1880929892857\n",
      "Test: 3 Test_Reward: 232.42593289194838\n",
      "Test: 4 Test_Reward: 273.6500263811837\n",
      "Test: 5 Test_Reward: 226.1602468803434\n",
      "Test: 6 Test_Reward: 287.3812678309893\n",
      "Test: 8 Test_Reward: 284.53310376749425\n",
      "Test: 9 Test_Reward: 281.5909848941346\n",
      "Test: 10 Test_Reward: 230.83513028376706\n",
      "Test: 11 Test_Reward: 283.48206863143764\n",
      "Test: 12 Test_Reward: 270.530306277858\n",
      "Test: 13 Test_Reward: 265.93506246224615\n",
      "Test: 14 Test_Reward: 294.9238454651828\n",
      "Test: 15 Test_Reward: 274.3982911667542\n",
      "Test: 16 Test_Reward: 273.37854454201965\n",
      "Test: 17 Test_Reward: 290.9974351488406\n",
      "Test: 18 Test_Reward: 297.15854609750704\n",
      "Test: 19 Test_Reward: 293.29487598216633\n",
      "Test: 20 Test_Reward: 256.2934396680771\n",
      "Test: 21 Test_Reward: 281.81252065873093\n",
      "Test: 22 Test_Reward: 280.0502988607407\n",
      "Test: 23 Test_Reward: 250.234617687204\n",
      "Test: 24 Test_Reward: 294.4018493710514\n",
      "Test: 25 Test_Reward: 309.71465851818243\n",
      "Test: 26 Test_Reward: 304.6379598464725\n",
      "Test: 27 Test_Reward: 274.2261598405581\n",
      "Test: 28 Test_Reward: 296.3232929365662\n",
      "Test: 29 Test_Reward: 235.4844344089033\n",
      "Test: 30 Test_Reward: 242.89424245332896\n",
      "Test: 32 Test_Reward: 236.8004332261779\n",
      "Test: 33 Test_Reward: 261.5460713519894\n",
      "Test: 34 Test_Reward: 275.7182534745663\n",
      "Test: 35 Test_Reward: 290.8140893404267\n",
      "Test: 36 Test_Reward: 297.6840909835355\n",
      "Test: 37 Test_Reward: 298.4165300214395\n",
      "Test: 38 Test_Reward: 259.6607036846975\n",
      "Test: 39 Test_Reward: 224.82328983830774\n",
      "Test: 40 Test_Reward: 250.40151875210026\n",
      "Test: 41 Test_Reward: 293.5194827086995\n",
      "Test: 42 Test_Reward: 242.6039765567633\n",
      "Test: 43 Test_Reward: 223.1222482972849\n",
      "Test: 44 Test_Reward: 245.47737352317898\n",
      "Test: 45 Test_Reward: 276.78345887825304\n",
      "Test: 46 Test_Reward: 263.4019164327964\n",
      "Test: 47 Test_Reward: 226.8625922367503\n",
      "Test: 48 Test_Reward: 251.743675149246\n",
      "Test: 49 Test_Reward: 247.41375775561835\n",
      "Test: 50 Test_Reward: 226.89241712629396\n",
      "Test: 51 Test_Reward: 299.8582137098109\n",
      "Test: 52 Test_Reward: 284.8356957950083\n",
      "Test: 53 Test_Reward: 236.31930952038257\n",
      "Test: 54 Test_Reward: 254.3167798583082\n",
      "Test: 55 Test_Reward: 288.47083989419184\n",
      "Test: 56 Test_Reward: 238.03595378037173\n",
      "Test: 57 Test_Reward: 286.30842617383894\n",
      "Test: 58 Test_Reward: 281.3854046679289\n",
      "Test: 59 Test_Reward: 289.5318655373254\n",
      "Test: 60 Test_Reward: 267.7821096083501\n",
      "Test: 61 Test_Reward: 286.86999861155994\n",
      "Test: 62 Test_Reward: 253.53320203362077\n",
      "Test: 63 Test_Reward: 250.14180711710858\n",
      "Test: 64 Test_Reward: 253.87157402368075\n",
      "Test: 65 Test_Reward: 281.01050446943117\n",
      "Test: 66 Test_Reward: 257.7896950445124\n",
      "Test: 67 Test_Reward: 254.09747920216552\n",
      "Test: 69 Test_Reward: 291.77700357185165\n",
      "Test: 70 Test_Reward: 274.6120153366636\n",
      "Test: 71 Test_Reward: 245.80285775712952\n",
      "Test: 74 Test_Reward: 290.64080867489355\n",
      "Test: 75 Test_Reward: 262.26670711115526\n",
      "Test: 76 Test_Reward: 254.41099488447105\n",
      "Test: 77 Test_Reward: 292.37731411936363\n",
      "Test: 78 Test_Reward: 240.5466594230537\n",
      "Test: 79 Test_Reward: 253.3175441320498\n",
      "Test: 80 Test_Reward: 276.68242305313277\n",
      "Test: 81 Test_Reward: 260.02730224804714\n",
      "Test: 82 Test_Reward: 254.90559875913735\n",
      "Test: 83 Test_Reward: 300.6449981569603\n",
      "Test: 84 Test_Reward: 245.16233478833925\n",
      "Test: 85 Test_Reward: 296.2037125135879\n",
      "Test: 87 Test_Reward: 258.08379768523923\n",
      "Test: 88 Test_Reward: 265.0054561085177\n",
      "Test: 90 Test_Reward: 285.6863078260659\n",
      "Test: 91 Test_Reward: 259.6846362729171\n",
      "Test: 92 Test_Reward: 299.9633088034321\n",
      "Test: 93 Test_Reward: 228.35077874506894\n",
      "Test: 94 Test_Reward: 245.98974251554412\n",
      "Test: 95 Test_Reward: 285.43017949681183\n",
      "Test: 96 Test_Reward: 301.30930552563836\n",
      "Test: 97 Test_Reward: 254.58977193090834\n",
      "Test: 98 Test_Reward: 280.8545611290999\n",
      "Test: 99 Test_Reward: 268.94901041707124\n",
      "Test finished with success 92 out of 100 iterations.\n",
      "Test average reward is 248.86134427146646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 900/3000 [1:11:28<12:24:24, 21.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 900 Episodic_Reward: 264.79653561274733\n",
      "Success in episode 900 with a reward of 264.79653561274733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 901/3000 [1:11:29<8:53:00, 15.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 901 with a reward of 258.3355260097435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 902/3000 [1:11:30<6:23:14, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 902 with a reward of 282.19777869954873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 903/3000 [1:11:31<4:40:44,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 903 with a reward of 229.49575961794247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 904/3000 [1:11:32<3:27:30,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 904 with a reward of 253.70308080873204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 906/3000 [1:11:54<4:21:10,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 906 with a reward of 271.3386265877655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 907/3000 [1:11:55<3:13:54,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 907 with a reward of 237.50536901287626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 908/3000 [1:11:56<2:27:36,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 908 with a reward of 255.73510892792373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 909/3000 [1:11:57<1:54:38,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 909 with a reward of 267.16414727371466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 910/3000 [1:12:18<4:58:54,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes: 910 Episodic_Reward: 225.38423146387902\n",
      "Success in episode 910 with a reward of 225.38423146387902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 911/3000 [1:12:19<3:40:26,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 911 with a reward of 257.33008568080436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 912/3000 [1:12:20<2:45:54,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 912 with a reward of 257.3508828649315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 913/3000 [1:12:21<2:08:26,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 913 with a reward of 270.8123953750912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 914/3000 [1:12:23<1:42:34,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success in episode 914 with a reward of 274.19803084604035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 914/3000 [1:12:26<2:45:20,  4.76s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ff77a2633683>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mPPO_agent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPPO_agent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-a35ae078265e>\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(agent, num_episodes, max_count, load)\u001b[0m\n\u001b[0;32m    147\u001b[0m                     \u001b[1;31m#####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m                     \u001b[0moptimize_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstates_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactions_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madv_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mref_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mold_logprob_v_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[1;31m#####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-53bf5735daa7>\u001b[0m in \u001b[0;36moptimize_network\u001b[1;34m(agent, states, actions, adv_batch, ref_batch, batch_old_logprob_v)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_crit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_act\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer_env\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduced_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m       return distribute_ctx.get_replica_context().merge_call(\n\u001b[0m\u001b[0;32m    546\u001b[0m           \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distributed_apply\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapply_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer_env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[1;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[0;32m   2714\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 2715\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer_env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[1;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2720\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[0;32m   2721\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2722\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2723\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2724\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer_env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer_env\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[1;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[0;32m    630\u001b[0m           with ops.name_scope(\"update\" if eagerly_outside_functions else\n\u001b[0;32m    631\u001b[0m                               \"update_\" + var.op.name, skip_on_eager=True):\n\u001b[1;32m--> 632\u001b[1;33m             update_ops.extend(distribution.extended.update(\n\u001b[0m\u001b[0;32m    633\u001b[0m                 var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer_env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   2298\u001b[0m         fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m   2299\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2300\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2302\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer_env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   2953\u001b[0m     \u001b[1;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2954\u001b[0m     \u001b[1;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2955\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2957\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer_env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[1;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[0;32m   2959\u001b[0m     \u001b[1;31m# once that value is used for something.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2960\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2961\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2962\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2963\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer_env\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer_env\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[1;34m(var, grad)\u001b[0m\n\u001b[0;32m    606\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m\"apply_state\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"apply_state\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer_env\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[1;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m       return training_ops.resource_apply_adam(\n\u001b[0m\u001b[0;32m    175\u001b[0m           \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m           \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\transformer_env\\lib\\site-packages\\tensorflow\\python\\training\\gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adam\u001b[1;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[0;32m   1421\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1423\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   1424\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ResourceApplyAdam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta1_power\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta2_power\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PPO_agent = Agent\n",
    "run_experiment(PPO_agent,3000, 0, load = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_agent.critic.save_weights(\"G:/My Drive/JAXA/2020-2021/Transformer/weights/PPO_Lander_critic_BEST\" + \".h5\")\n",
    "PPO_agent.actor.save_weights(\"G:/My Drive/JAXA/2020-2021/Transformer/weights/PPO_Lander_actor_BEST\" + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_agent.distribution_buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_agent.last_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.squeeze(PPO_agent.last_action).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of Transformer-Normal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
